{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123376"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "\n",
    "with open('./spa-eng/spa.txt') as f:\n",
    "    spa_eng_list = f.read().strip().split('\\n')\n",
    "\n",
    "len(spa_eng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>Now move on.</td>\n",
       "      <td>Ahora prosigue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>Never say that.</td>\n",
       "      <td>Nunca digas eso.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>Everybody paid.</td>\n",
       "      <td>Todos pagaron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>Where are you?</td>\n",
       "      <td>¿Dónde estás?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>Tom likes me.</td>\n",
       "      <td>Le gusto a Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Be merciful.</td>\n",
       "      <td>Sé clemente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>Who wants that?</td>\n",
       "      <td>¿Quién quiere eso?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>Is this mine?</td>\n",
       "      <td>¿Es éste el mío?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9517</th>\n",
       "      <td>Tom called Mary.</td>\n",
       "      <td>Tom llamó a Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>I want my money.</td>\n",
       "      <td>Quiero mi plata.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eng                  es\n",
       "2216      Now move on.     Ahora prosigue.\n",
       "6843   Never say that.    Nunca digas eso.\n",
       "5952   Everybody paid.      Todos pagaron.\n",
       "5625    Where are you?       ¿Dónde estás?\n",
       "3622     Tom likes me.     Le gusto a Tom.\n",
       "1698      Be merciful.        Sé clemente.\n",
       "7562   Who wants that?  ¿Quién quiere eso?\n",
       "3183     Is this mine?    ¿Es éste el mío?\n",
       "9517  Tom called Mary.   Tom llamó a Mary.\n",
       "8532  I want my money.    Quiero mi plata."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample size\n",
    "num_examples = 10000\n",
    "\n",
    "# creates lists containing each pair\n",
    "original_word_pairs = [[w for w in l.split('\\t')] for l in spa_eng_list[:num_examples]]\n",
    "\n",
    "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    \"\"\"\n",
    "    Normalizes latin chars with accent to their canonical decomposition\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def pad_sequences(x, max_len):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    if len(x) > max_len:\n",
    "        padded[:] = x[:max_len]\n",
    "    else:\n",
    "        padded[:len(x)] = x\n",
    "    return padded\n",
    "\n",
    "# sort batch function to be able to use with pad_packed_sequence\n",
    "def sort_batch(X, y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>&lt;start&gt; my shoes squeak . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; mis zapatos chirrian . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>&lt;start&gt; it s not my car . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; no es mi auto . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>&lt;start&gt; we need a plan . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; necesitamos un plan . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>&lt;start&gt; hold still . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; mantente quieto . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>&lt;start&gt; we want it . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; lo queremos . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>&lt;start&gt; i m a christian . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; soy cristiano . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>&lt;start&gt; i let you win . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; yo te dejo ganar . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>&lt;start&gt; i fell for it . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; me enganaron a causa de eso . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>&lt;start&gt; this is japan . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; esto es el japon . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7961</th>\n",
       "      <td>&lt;start&gt; even tom smiled . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; incluso tom sonrio . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  eng  \\\n",
       "9046  <start> my shoes squeak . <end>   \n",
       "8894  <start> it s not my car . <end>   \n",
       "7445   <start> we need a plan . <end>   \n",
       "1108       <start> hold still . <end>   \n",
       "1612       <start> we want it . <end>   \n",
       "8628  <start> i m a christian . <end>   \n",
       "4482    <start> i let you win . <end>   \n",
       "4396    <start> i fell for it . <end>   \n",
       "5324    <start> this is japan . <end>   \n",
       "7961  <start> even tom smiled . <end>   \n",
       "\n",
       "                                               es  \n",
       "9046         <start> mis zapatos chirrian . <end>  \n",
       "8894                <start> no es mi auto . <end>  \n",
       "7445          <start> necesitamos un plan . <end>  \n",
       "1108              <start> mantente quieto . <end>  \n",
       "1612                  <start> lo queremos . <end>  \n",
       "8628                <start> soy cristiano . <end>  \n",
       "4482             <start> yo te dejo ganar . <end>  \n",
       "4396  <start> me enganaron a causa de eso . <end>  \n",
       "5324             <start> esto es el japon . <end>  \n",
       "7961           <start> incluso tom sonrio . <end>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process the data\n",
    "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
    "data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary\n",
    "class LanguageIndex():\n",
    "    \n",
    "    def __init__(self, lang):\n",
    "        \"\"\" lang: the list of phrases from each language \"\"\"\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "        \n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            # update with individual tokens\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "            \n",
    "        # sort the vocab\n",
    "        self.vocab = sorted(self.vocab)\n",
    "\n",
    "        # add a padding token with index 0\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        \n",
    "        # word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
    "        \n",
    "        # index to word mapping\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 4361, 3, 4], [5, 4425, 3, 4], [5, 4353, 3, 4], [5, 4360, 3, 4], [5, 2221, 3, 4]]\n",
      "[[5, 843, 3, 4], [5, 843, 3, 4], [5, 843, 3, 4], [5, 843, 3, 4], [5, 944, 3, 4]]\n",
      "max_length_inp: 12\n",
      "max_length_tar: 8\n",
      "len(input_tensor): 10000\n",
      "len(target_tensor): 10000\n",
      "len(input_tensor_train): 8000\n",
      "len(target_tensor_train): 8000\n",
      "len(input_tensor_val): 2000\n",
      "len(target_tensor_val): 2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index language using the class above\n",
    "inp_lang = LanguageIndex(data[\"es\"].values.tolist())\n",
    "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
    "\n",
    "# Vectorize the input and target languages\n",
    "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n",
    "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]\n",
    "print(input_tensor[:5])\n",
    "print(target_tensor[:5])\n",
    "\n",
    "# calculate the max_length of input and output tensor\n",
    "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "print('max_length_inp: %d'%max_length_inp)\n",
    "print('max_length_tar: %d'%max_length_tar)\n",
    "\n",
    "# inplace padding\n",
    "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
    "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
    "print('len(input_tensor): %d'%len(input_tensor))\n",
    "print('len(target_tensor): %d'%len(target_tensor))\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "print('len(input_tensor_train): %d\\nlen(target_tensor_train): %d\\nlen(input_tensor_val): %d\\nlen(target_tensor_val): %d\\n'\n",
    "       % (len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2285"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targ_lang.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver the data to tensors and pass to the Dataloader to create an batch iterator\n",
    "class IterData(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        x_len = self.length[index]\n",
    "        return x, y, x_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 16\n",
    "N_BATCH = BUFFER_SIZE // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "train_dataset = IterData(input_tensor_train, target_tensor_train)\n",
    "val_dataset = IterData(input_tensor_val, target_tensor_val)\n",
    "\n",
    "dataset_train = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)\n",
    "\n",
    "dataset_val = DataLoader(val_dataset, batch_size = 1, \n",
    "                     drop_last=True,\n",
    "                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
    "        \n",
    "    def forward(self, x, lens,  device):\n",
    "        # x: (batch_size, max_length, embedding_dim)\n",
    "        x = self.embedding(x) \n",
    "        x = pack_padded_sequence(x, lens)\n",
    "        \n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "        \n",
    "        output, self.hidden = self.gru(x, self.hidden)\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, self.hidden\n",
    "        \n",
    "    def initialize_hidden_state(self, device):\n",
    "        return torch.zeros((1, self.batch_size, self.enc_units)).to(device)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim + self.enc_units,\n",
    "                                         self.dec_units,\n",
    "                                         batch_first=True)\n",
    "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
    "        \n",
    "        # for attention\n",
    "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.V = nn.Linear(self.enc_units, 1)\n",
    "        \n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        # enc_output original: (max_length, batch_size, enc_units)\n",
    "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
    "        enc_output = enc_output.permute(1, 0, 2)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
    "        \n",
    "        # score: (batch_size, max_length, hidden_size)\n",
    "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # Looks like attention vector in diagram of source\n",
    "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output: (batch_size, 1, hidden_size)\n",
    "        output, state = self.gru(x)\n",
    "            \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output =  output.view(-1, output.size(2))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return torch.zeros((1, self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_fuction(real, pred):\n",
    "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
    "    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
    "    #print(mask)\n",
    "    mask = real.ge(1).type(torch.FloatTensor)\n",
    "#     mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on CPU\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(' Train on ' + str(device).upper())\n",
    "\n",
    "PRE_TRAINED = True\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "\n",
    "if PRE_TRAINED:\n",
    "    encoder.load_state_dict(torch.load('eng2spa_encoder_params.pkl'))\n",
    "    decoder.load_state_dict(torch.load('eng2spa_decoder_params.pkl'))\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "def train(encoder, decoder, epoch):\n",
    "    losses = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, (inp, targ, inp_len) in enumerate(dataset_train):\n",
    "        loss = 0\n",
    "\n",
    "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
    "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
    "        \n",
    "        end = time.time()\n",
    "\n",
    "        for t in range(1, ys.size(1)):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
    "                                                                            dec_hidden.to(device),\n",
    "                                                                            enc_output.to(device))\n",
    "            loss += loss_fuction(ys[:, t].to(device), predictions.to(device))\n",
    "            dec_input = ys[:, t].unsqueeze(1)\n",
    "\n",
    "        batch_loss = (loss / int(ys.size(1)))\n",
    "        losses.update(batch_loss, xs.size(0))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch % PRINT_FREQ == 0:\n",
    "                print('Epoch: [{0}] [{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      .format(\n",
    "                       epoch, batch, len(dataset_train), batch_time=batch_time, loss=losses))\n",
    "                \n",
    "#         print('Saving Model...')\n",
    "#         torch.save(encoder.state_dict(), 'eng2spa_encoder_params.pkl')\n",
    "#         torch.save(decoder.state_dict(), 'eng2spa_decoder_params.pkl')\n",
    "#         print('Model Saved Successfully!')\n",
    "        if batch % 200 == 0:\n",
    "            print('Saving Model...')\n",
    "            torch.save(encoder.state_dict(), 'eng2spa_encoder_params.pkl')\n",
    "            torch.save(decoder.state_dict(), 'eng2spa_decoder_params.pkl')\n",
    "            print('Model Saved Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(encoder, decoder):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    acc = 0\n",
    "    for batch, (inp, targ, inp_len) in enumerate(dataset_val):\n",
    "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
    "        raw_sen = xs.numpy()\n",
    "        print(raw_sen.shape)\n",
    "        for raw_word in raw_sen:\n",
    "#             print(raw_word)\n",
    "            print(inp_lang.idx2word[int(raw_word)], end=' ')\n",
    "        print()\n",
    "        raw_sen1 = ys.numpy()[0]\n",
    "        print(raw_sen1.shape)\n",
    "        for raw_word1 in raw_sen1:\n",
    "#             print(raw_word)\n",
    "            print(targ_lang.idx2word[int(raw_word1)], end=' ')\n",
    "        print()\n",
    "        input()\n",
    "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * 1)\n",
    "        for t in range(1, ys.size(1)):\n",
    "            print(ys.size(1))\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
    "                                                                            dec_hidden.to(device),\n",
    "                                                                            enc_output.to(device))\n",
    "#             print(predictions.shape)\n",
    "#             print(ys[:,t])\n",
    "            pred = torch.argmax(predictions)\n",
    "#             print(predictions.detach().numpy())\n",
    "#             print(predictions.detach().numpy()[0][3])\n",
    "#             print(int(pred.numpy()))\n",
    "            print(targ_lang.idx2word[int(pred.numpy())], end=' ')\n",
    "        print()\n",
    "#             input()\n",
    "#         print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(encoder, decoder):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    x = input('Input an Spanish sentence to translate: ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] [0/500]\tTime 0.765 (0.765)\tLoss 5.3143 (5.3143)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [0] [5/500]\tTime 0.577 (0.610)\tLoss 3.2598 (4.1514)\t\n",
      "Epoch: [0] [10/500]\tTime 0.705 (0.632)\tLoss 2.8092 (3.6033)\t\n",
      "Epoch: [0] [15/500]\tTime 0.551 (0.689)\tLoss 2.6122 (3.3181)\t\n",
      "Epoch: [0] [20/500]\tTime 0.605 (0.665)\tLoss 2.7339 (3.1550)\t\n",
      "Epoch: [0] [25/500]\tTime 0.708 (0.660)\tLoss 2.4596 (3.0170)\t\n",
      "Epoch: [0] [30/500]\tTime 0.743 (0.653)\tLoss 2.4999 (2.9261)\t\n",
      "Epoch: [0] [35/500]\tTime 0.709 (0.654)\tLoss 2.4487 (2.8500)\t\n",
      "Epoch: [0] [40/500]\tTime 0.826 (0.670)\tLoss 2.1671 (2.7750)\t\n",
      "Epoch: [0] [45/500]\tTime 0.761 (0.668)\tLoss 2.3109 (2.7176)\t\n",
      "Epoch: [0] [50/500]\tTime 0.545 (0.657)\tLoss 2.2816 (2.6736)\t\n",
      "Epoch: [0] [55/500]\tTime 0.536 (0.650)\tLoss 2.1968 (2.6231)\t\n",
      "Epoch: [0] [60/500]\tTime 0.528 (0.641)\tLoss 2.1722 (2.5816)\t\n",
      "Epoch: [0] [65/500]\tTime 0.544 (0.634)\tLoss 2.1068 (2.5453)\t\n",
      "Epoch: [0] [70/500]\tTime 0.552 (0.628)\tLoss 1.9087 (2.5130)\t\n",
      "Epoch: [0] [75/500]\tTime 0.575 (0.624)\tLoss 2.0126 (2.4869)\t\n",
      "Epoch: [0] [80/500]\tTime 0.532 (0.619)\tLoss 1.9094 (2.4545)\t\n",
      "Epoch: [0] [85/500]\tTime 0.552 (0.615)\tLoss 2.1000 (2.4315)\t\n",
      "Epoch: [0] [90/500]\tTime 0.577 (0.612)\tLoss 1.8975 (2.4061)\t\n",
      "Epoch: [0] [95/500]\tTime 0.525 (0.608)\tLoss 1.7931 (2.3805)\t\n",
      "Epoch: [0] [100/500]\tTime 0.528 (0.606)\tLoss 1.6364 (2.3517)\t\n",
      "Epoch: [0] [105/500]\tTime 0.541 (0.605)\tLoss 1.9598 (2.3311)\t\n",
      "Epoch: [0] [110/500]\tTime 0.543 (0.603)\tLoss 1.7868 (2.3071)\t\n",
      "Epoch: [0] [115/500]\tTime 0.561 (0.601)\tLoss 1.7542 (2.2889)\t\n",
      "Epoch: [0] [120/500]\tTime 0.528 (0.599)\tLoss 1.8346 (2.2691)\t\n",
      "Epoch: [0] [125/500]\tTime 0.571 (0.597)\tLoss 1.6974 (2.2501)\t\n",
      "Epoch: [0] [130/500]\tTime 0.567 (0.596)\tLoss 1.8933 (2.2310)\t\n",
      "Epoch: [0] [135/500]\tTime 0.552 (0.594)\tLoss 1.8045 (2.2128)\t\n",
      "Epoch: [0] [140/500]\tTime 0.535 (0.593)\tLoss 1.8834 (2.1965)\t\n",
      "Epoch: [0] [145/500]\tTime 0.551 (0.591)\tLoss 1.8931 (2.1845)\t\n",
      "Epoch: [0] [150/500]\tTime 0.543 (0.590)\tLoss 1.9675 (2.1708)\t\n",
      "Epoch: [0] [155/500]\tTime 0.545 (0.589)\tLoss 1.7304 (2.1578)\t\n",
      "Epoch: [0] [160/500]\tTime 0.542 (0.587)\tLoss 1.5452 (2.1440)\t\n",
      "Epoch: [0] [165/500]\tTime 0.645 (0.587)\tLoss 1.8825 (2.1305)\t\n",
      "Epoch: [0] [170/500]\tTime 0.543 (0.586)\tLoss 1.4070 (2.1189)\t\n",
      "Epoch: [0] [175/500]\tTime 0.545 (0.585)\tLoss 2.1696 (2.1088)\t\n",
      "Epoch: [0] [180/500]\tTime 0.537 (0.585)\tLoss 1.6525 (2.0937)\t\n",
      "Epoch: [0] [185/500]\tTime 0.538 (0.583)\tLoss 1.5559 (2.0807)\t\n",
      "Epoch: [0] [190/500]\tTime 0.554 (0.583)\tLoss 1.3469 (2.0685)\t\n",
      "Epoch: [0] [195/500]\tTime 0.555 (0.583)\tLoss 1.7837 (2.0575)\t\n",
      "Epoch: [0] [200/500]\tTime 0.537 (0.582)\tLoss 1.6545 (2.0456)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [0] [205/500]\tTime 0.572 (0.582)\tLoss 1.7819 (2.0363)\t\n",
      "Epoch: [0] [210/500]\tTime 0.562 (0.581)\tLoss 1.4229 (2.0242)\t\n",
      "Epoch: [0] [215/500]\tTime 0.545 (0.580)\tLoss 1.6534 (2.0155)\t\n",
      "Epoch: [0] [220/500]\tTime 0.560 (0.580)\tLoss 1.6423 (2.0049)\t\n",
      "Epoch: [0] [225/500]\tTime 0.530 (0.579)\tLoss 1.5868 (1.9962)\t\n",
      "Epoch: [0] [230/500]\tTime 0.527 (0.579)\tLoss 1.6174 (1.9864)\t\n",
      "Epoch: [0] [235/500]\tTime 0.529 (0.578)\tLoss 1.8074 (1.9786)\t\n",
      "Epoch: [0] [240/500]\tTime 0.551 (0.578)\tLoss 1.6095 (1.9707)\t\n",
      "Epoch: [0] [245/500]\tTime 0.538 (0.577)\tLoss 1.3293 (1.9615)\t\n",
      "Epoch: [0] [250/500]\tTime 0.575 (0.577)\tLoss 1.5952 (1.9537)\t\n",
      "Epoch: [0] [255/500]\tTime 0.554 (0.577)\tLoss 1.6399 (1.9486)\t\n",
      "Epoch: [0] [260/500]\tTime 0.536 (0.577)\tLoss 1.3451 (1.9411)\t\n",
      "Epoch: [0] [265/500]\tTime 0.552 (0.576)\tLoss 1.3739 (1.9314)\t\n",
      "Epoch: [0] [270/500]\tTime 0.554 (0.576)\tLoss 1.4851 (1.9237)\t\n",
      "Epoch: [0] [275/500]\tTime 0.635 (0.576)\tLoss 1.6438 (1.9171)\t\n",
      "Epoch: [0] [280/500]\tTime 0.538 (0.576)\tLoss 1.4317 (1.9095)\t\n",
      "Epoch: [0] [285/500]\tTime 0.571 (0.576)\tLoss 1.3891 (1.9015)\t\n",
      "Epoch: [0] [290/500]\tTime 0.596 (0.577)\tLoss 1.5690 (1.8936)\t\n",
      "Epoch: [0] [295/500]\tTime 0.780 (0.579)\tLoss 1.7593 (1.8883)\t\n",
      "Epoch: [0] [300/500]\tTime 0.553 (0.580)\tLoss 1.3102 (1.8803)\t\n",
      "Epoch: [0] [305/500]\tTime 0.552 (0.579)\tLoss 1.3214 (1.8727)\t\n",
      "Epoch: [0] [310/500]\tTime 0.533 (0.579)\tLoss 1.5747 (1.8677)\t\n",
      "Epoch: [0] [315/500]\tTime 0.535 (0.578)\tLoss 1.1899 (1.8604)\t\n",
      "Epoch: [0] [320/500]\tTime 0.563 (0.578)\tLoss 1.3828 (1.8518)\t\n",
      "Epoch: [0] [325/500]\tTime 0.553 (0.578)\tLoss 1.5779 (1.8483)\t\n",
      "Epoch: [0] [330/500]\tTime 0.528 (0.577)\tLoss 1.2701 (1.8416)\t\n",
      "Epoch: [0] [335/500]\tTime 0.543 (0.577)\tLoss 1.3988 (1.8352)\t\n",
      "Epoch: [0] [340/500]\tTime 0.543 (0.577)\tLoss 1.3662 (1.8288)\t\n",
      "Epoch: [0] [345/500]\tTime 0.543 (0.577)\tLoss 1.3588 (1.8226)\t\n",
      "Epoch: [0] [350/500]\tTime 0.544 (0.576)\tLoss 1.3748 (1.8160)\t\n",
      "Epoch: [0] [355/500]\tTime 0.551 (0.576)\tLoss 1.4574 (1.8102)\t\n",
      "Epoch: [0] [360/500]\tTime 0.552 (0.576)\tLoss 1.4130 (1.8050)\t\n",
      "Epoch: [0] [365/500]\tTime 0.564 (0.576)\tLoss 1.4400 (1.7999)\t\n",
      "Epoch: [0] [370/500]\tTime 0.587 (0.576)\tLoss 1.5333 (1.7939)\t\n",
      "Epoch: [0] [375/500]\tTime 0.533 (0.575)\tLoss 1.4718 (1.7880)\t\n",
      "Epoch: [0] [380/500]\tTime 0.554 (0.575)\tLoss 1.4638 (1.7826)\t\n",
      "Epoch: [0] [385/500]\tTime 0.545 (0.575)\tLoss 1.5421 (1.7786)\t\n",
      "Epoch: [0] [390/500]\tTime 0.585 (0.574)\tLoss 1.2506 (1.7724)\t\n",
      "Epoch: [0] [395/500]\tTime 0.528 (0.574)\tLoss 1.4343 (1.7674)\t\n",
      "Epoch: [0] [400/500]\tTime 0.634 (0.574)\tLoss 1.5114 (1.7616)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [0] [405/500]\tTime 0.539 (0.574)\tLoss 1.1923 (1.7578)\t\n",
      "Epoch: [0] [410/500]\tTime 0.558 (0.574)\tLoss 1.1770 (1.7507)\t\n",
      "Epoch: [0] [415/500]\tTime 0.553 (0.573)\tLoss 1.2420 (1.7454)\t\n",
      "Epoch: [0] [420/500]\tTime 0.556 (0.573)\tLoss 1.4589 (1.7403)\t\n",
      "Epoch: [0] [425/500]\tTime 0.555 (0.573)\tLoss 1.0104 (1.7358)\t\n",
      "Epoch: [0] [430/500]\tTime 0.528 (0.573)\tLoss 1.3037 (1.7308)\t\n",
      "Epoch: [0] [435/500]\tTime 0.545 (0.573)\tLoss 1.3495 (1.7272)\t\n",
      "Epoch: [0] [440/500]\tTime 0.527 (0.572)\tLoss 1.4004 (1.7226)\t\n",
      "Epoch: [0] [445/500]\tTime 0.547 (0.572)\tLoss 0.9701 (1.7158)\t\n",
      "Epoch: [0] [450/500]\tTime 0.524 (0.572)\tLoss 1.1520 (1.7116)\t\n",
      "Epoch: [0] [455/500]\tTime 0.647 (0.572)\tLoss 1.2309 (1.7052)\t\n",
      "Epoch: [0] [460/500]\tTime 0.566 (0.572)\tLoss 1.2468 (1.7007)\t\n",
      "Epoch: [0] [465/500]\tTime 0.551 (0.572)\tLoss 0.9172 (1.6942)\t\n",
      "Epoch: [0] [470/500]\tTime 0.534 (0.571)\tLoss 1.0498 (1.6891)\t\n",
      "Epoch: [0] [475/500]\tTime 0.632 (0.571)\tLoss 1.2845 (1.6844)\t\n",
      "Epoch: [0] [480/500]\tTime 0.554 (0.571)\tLoss 1.4728 (1.6808)\t\n",
      "Epoch: [0] [485/500]\tTime 0.556 (0.571)\tLoss 1.1950 (1.6758)\t\n",
      "Epoch: [0] [490/500]\tTime 0.573 (0.571)\tLoss 1.2832 (1.6721)\t\n",
      "Epoch: [0] [495/500]\tTime 0.557 (0.571)\tLoss 1.2811 (1.6675)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [1] [0/500]\tTime 0.565 (0.565)\tLoss 1.1572 (1.1572)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [1] [5/500]\tTime 0.545 (0.552)\tLoss 1.0069 (0.9773)\t\n",
      "Epoch: [1] [10/500]\tTime 0.521 (0.547)\tLoss 0.8549 (0.9715)\t\n",
      "Epoch: [1] [15/500]\tTime 0.555 (0.553)\tLoss 0.8360 (0.9401)\t\n",
      "Epoch: [1] [20/500]\tTime 0.538 (0.550)\tLoss 0.8296 (0.9216)\t\n",
      "Epoch: [1] [25/500]\tTime 0.572 (0.555)\tLoss 0.8204 (0.9176)\t\n",
      "Epoch: [1] [30/500]\tTime 0.540 (0.556)\tLoss 0.8021 (0.9055)\t\n",
      "Epoch: [1] [35/500]\tTime 0.638 (0.575)\tLoss 1.0122 (0.8988)\t\n",
      "Epoch: [1] [40/500]\tTime 0.570 (0.577)\tLoss 0.9193 (0.8958)\t\n",
      "Epoch: [1] [45/500]\tTime 0.567 (0.574)\tLoss 1.0180 (0.9042)\t\n",
      "Epoch: [1] [50/500]\tTime 0.551 (0.573)\tLoss 1.0827 (0.9002)\t\n",
      "Epoch: [1] [55/500]\tTime 0.523 (0.570)\tLoss 0.8121 (0.8929)\t\n",
      "Epoch: [1] [60/500]\tTime 0.556 (0.570)\tLoss 0.9834 (0.8989)\t\n",
      "Epoch: [1] [65/500]\tTime 0.539 (0.569)\tLoss 0.4605 (0.8888)\t\n",
      "Epoch: [1] [70/500]\tTime 0.539 (0.568)\tLoss 0.8798 (0.8953)\t\n",
      "Epoch: [1] [75/500]\tTime 0.541 (0.566)\tLoss 1.2145 (0.9071)\t\n",
      "Epoch: [1] [80/500]\tTime 0.548 (0.565)\tLoss 0.8865 (0.9057)\t\n",
      "Epoch: [1] [85/500]\tTime 0.548 (0.564)\tLoss 0.7836 (0.9050)\t\n",
      "Epoch: [1] [90/500]\tTime 0.563 (0.564)\tLoss 0.8994 (0.9130)\t\n",
      "Epoch: [1] [95/500]\tTime 0.561 (0.564)\tLoss 1.0490 (0.9148)\t\n",
      "Epoch: [1] [100/500]\tTime 0.530 (0.563)\tLoss 0.7299 (0.9145)\t\n",
      "Epoch: [1] [105/500]\tTime 0.564 (0.564)\tLoss 0.9246 (0.9117)\t\n",
      "Epoch: [1] [110/500]\tTime 0.555 (0.563)\tLoss 0.8546 (0.9138)\t\n",
      "Epoch: [1] [115/500]\tTime 0.538 (0.562)\tLoss 0.8934 (0.9133)\t\n",
      "Epoch: [1] [120/500]\tTime 0.521 (0.562)\tLoss 0.6999 (0.9057)\t\n",
      "Epoch: [1] [125/500]\tTime 0.605 (0.562)\tLoss 0.9701 (0.9046)\t\n",
      "Epoch: [1] [130/500]\tTime 0.539 (0.562)\tLoss 0.8464 (0.9044)\t\n",
      "Epoch: [1] [135/500]\tTime 0.551 (0.561)\tLoss 0.8241 (0.9034)\t\n",
      "Epoch: [1] [140/500]\tTime 0.530 (0.560)\tLoss 0.8127 (0.8989)\t\n",
      "Epoch: [1] [145/500]\tTime 0.637 (0.561)\tLoss 1.0253 (0.9001)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1] [150/500]\tTime 0.554 (0.561)\tLoss 0.8190 (0.9004)\t\n",
      "Epoch: [1] [155/500]\tTime 0.533 (0.561)\tLoss 0.8236 (0.9027)\t\n",
      "Epoch: [1] [160/500]\tTime 0.540 (0.561)\tLoss 0.9452 (0.9044)\t\n",
      "Epoch: [1] [165/500]\tTime 0.539 (0.560)\tLoss 0.7940 (0.9018)\t\n",
      "Epoch: [1] [170/500]\tTime 0.529 (0.560)\tLoss 0.8942 (0.9009)\t\n",
      "Epoch: [1] [175/500]\tTime 0.742 (0.561)\tLoss 0.9095 (0.9029)\t\n",
      "Epoch: [1] [180/500]\tTime 0.551 (0.563)\tLoss 0.8019 (0.9025)\t\n",
      "Epoch: [1] [185/500]\tTime 0.550 (0.563)\tLoss 0.8561 (0.9024)\t\n",
      "Epoch: [1] [190/500]\tTime 0.551 (0.563)\tLoss 0.8122 (0.9004)\t\n",
      "Epoch: [1] [195/500]\tTime 0.549 (0.563)\tLoss 0.9398 (0.9025)\t\n",
      "Epoch: [1] [200/500]\tTime 0.525 (0.562)\tLoss 1.0656 (0.9029)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [1] [205/500]\tTime 0.635 (0.564)\tLoss 0.6626 (0.9005)\t\n",
      "Epoch: [1] [210/500]\tTime 0.540 (0.563)\tLoss 0.9163 (0.8993)\t\n",
      "Epoch: [1] [215/500]\tTime 0.559 (0.563)\tLoss 0.8854 (0.9018)\t\n",
      "Epoch: [1] [220/500]\tTime 0.551 (0.563)\tLoss 0.6204 (0.9021)\t\n",
      "Epoch: [1] [225/500]\tTime 0.555 (0.563)\tLoss 0.9288 (0.9032)\t\n",
      "Epoch: [1] [230/500]\tTime 0.546 (0.562)\tLoss 0.8531 (0.9048)\t\n",
      "Epoch: [1] [235/500]\tTime 0.533 (0.562)\tLoss 0.8948 (0.9049)\t\n",
      "Epoch: [1] [240/500]\tTime 0.553 (0.562)\tLoss 0.9149 (0.9056)\t\n",
      "Epoch: [1] [245/500]\tTime 0.552 (0.562)\tLoss 0.7980 (0.9051)\t\n",
      "Epoch: [1] [250/500]\tTime 0.541 (0.562)\tLoss 0.7478 (0.9032)\t\n",
      "Epoch: [1] [255/500]\tTime 0.524 (0.562)\tLoss 0.7618 (0.9023)\t\n",
      "Epoch: [1] [260/500]\tTime 0.564 (0.562)\tLoss 0.6980 (0.9023)\t\n",
      "Epoch: [1] [265/500]\tTime 0.559 (0.562)\tLoss 0.8181 (0.9006)\t\n",
      "Epoch: [1] [270/500]\tTime 0.527 (0.562)\tLoss 1.0650 (0.9002)\t\n",
      "Epoch: [1] [275/500]\tTime 0.544 (0.562)\tLoss 0.6941 (0.8988)\t\n",
      "Epoch: [1] [280/500]\tTime 0.552 (0.562)\tLoss 0.5754 (0.8958)\t\n",
      "Epoch: [1] [285/500]\tTime 0.556 (0.562)\tLoss 0.8109 (0.8954)\t\n",
      "Epoch: [1] [290/500]\tTime 0.770 (0.563)\tLoss 1.1805 (0.8963)\t\n",
      "Epoch: [1] [295/500]\tTime 0.674 (0.563)\tLoss 0.6847 (0.8944)\t\n",
      "Epoch: [1] [300/500]\tTime 0.560 (0.563)\tLoss 0.9922 (0.8947)\t\n",
      "Epoch: [1] [305/500]\tTime 0.554 (0.563)\tLoss 0.8900 (0.8936)\t\n",
      "Epoch: [1] [310/500]\tTime 0.553 (0.563)\tLoss 0.8008 (0.8919)\t\n",
      "Epoch: [1] [315/500]\tTime 0.554 (0.562)\tLoss 0.9206 (0.8892)\t\n",
      "Epoch: [1] [320/500]\tTime 0.551 (0.562)\tLoss 0.6978 (0.8881)\t\n",
      "Epoch: [1] [325/500]\tTime 0.550 (0.562)\tLoss 0.8639 (0.8876)\t\n",
      "Epoch: [1] [330/500]\tTime 0.543 (0.562)\tLoss 0.9046 (0.8876)\t\n",
      "Epoch: [1] [335/500]\tTime 0.563 (0.562)\tLoss 1.1256 (0.8877)\t\n",
      "Epoch: [1] [340/500]\tTime 0.558 (0.562)\tLoss 0.7468 (0.8868)\t\n",
      "Epoch: [1] [345/500]\tTime 0.655 (0.562)\tLoss 1.0165 (0.8866)\t\n",
      "Epoch: [1] [350/500]\tTime 0.561 (0.564)\tLoss 1.0859 (0.8868)\t\n",
      "Epoch: [1] [355/500]\tTime 0.556 (0.563)\tLoss 0.8188 (0.8869)\t\n",
      "Epoch: [1] [360/500]\tTime 0.551 (0.563)\tLoss 0.7584 (0.8863)\t\n",
      "Epoch: [1] [365/500]\tTime 0.549 (0.563)\tLoss 0.9766 (0.8863)\t\n",
      "Epoch: [1] [370/500]\tTime 0.578 (0.563)\tLoss 1.1416 (0.8870)\t\n",
      "Epoch: [1] [375/500]\tTime 0.645 (0.564)\tLoss 0.5616 (0.8858)\t\n",
      "Epoch: [1] [380/500]\tTime 0.577 (0.565)\tLoss 0.8399 (0.8847)\t\n",
      "Epoch: [1] [385/500]\tTime 0.560 (0.566)\tLoss 0.7910 (0.8834)\t\n",
      "Epoch: [1] [390/500]\tTime 0.530 (0.565)\tLoss 0.9583 (0.8835)\t\n",
      "Epoch: [1] [395/500]\tTime 0.531 (0.565)\tLoss 0.9359 (0.8817)\t\n",
      "Epoch: [1] [400/500]\tTime 0.565 (0.565)\tLoss 0.6464 (0.8807)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [1] [405/500]\tTime 0.543 (0.565)\tLoss 0.6558 (0.8807)\t\n",
      "Epoch: [1] [410/500]\tTime 0.524 (0.565)\tLoss 0.8388 (0.8806)\t\n",
      "Epoch: [1] [415/500]\tTime 0.526 (0.564)\tLoss 0.8423 (0.8798)\t\n",
      "Epoch: [1] [420/500]\tTime 0.591 (0.564)\tLoss 0.9940 (0.8789)\t\n",
      "Epoch: [1] [425/500]\tTime 0.564 (0.564)\tLoss 0.7494 (0.8773)\t\n",
      "Epoch: [1] [430/500]\tTime 0.546 (0.564)\tLoss 0.7469 (0.8764)\t\n",
      "Epoch: [1] [435/500]\tTime 0.528 (0.564)\tLoss 0.7376 (0.8770)\t\n",
      "Epoch: [1] [440/500]\tTime 0.558 (0.563)\tLoss 1.0442 (0.8770)\t\n",
      "Epoch: [1] [445/500]\tTime 0.560 (0.563)\tLoss 0.6529 (0.8765)\t\n",
      "Epoch: [1] [450/500]\tTime 0.561 (0.563)\tLoss 0.9574 (0.8769)\t\n",
      "Epoch: [1] [455/500]\tTime 0.547 (0.563)\tLoss 1.0427 (0.8768)\t\n",
      "Epoch: [1] [460/500]\tTime 0.580 (0.563)\tLoss 0.7496 (0.8752)\t\n",
      "Epoch: [1] [465/500]\tTime 0.546 (0.563)\tLoss 1.0624 (0.8757)\t\n",
      "Epoch: [1] [470/500]\tTime 0.590 (0.562)\tLoss 1.1407 (0.8767)\t\n",
      "Epoch: [1] [475/500]\tTime 0.522 (0.562)\tLoss 0.8545 (0.8764)\t\n",
      "Epoch: [1] [480/500]\tTime 0.574 (0.562)\tLoss 0.8332 (0.8759)\t\n",
      "Epoch: [1] [485/500]\tTime 0.555 (0.562)\tLoss 0.6629 (0.8757)\t\n",
      "Epoch: [1] [490/500]\tTime 0.541 (0.562)\tLoss 0.8218 (0.8751)\t\n",
      "Epoch: [1] [495/500]\tTime 0.529 (0.562)\tLoss 0.7332 (0.8743)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [2] [0/500]\tTime 0.559 (0.559)\tLoss 0.4653 (0.4653)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [2] [5/500]\tTime 0.710 (0.592)\tLoss 0.4991 (0.4760)\t\n",
      "Epoch: [2] [10/500]\tTime 0.605 (0.620)\tLoss 0.4643 (0.4382)\t\n",
      "Epoch: [2] [15/500]\tTime 0.553 (0.608)\tLoss 0.5162 (0.4342)\t\n",
      "Epoch: [2] [20/500]\tTime 0.529 (0.591)\tLoss 0.4647 (0.4393)\t\n",
      "Epoch: [2] [25/500]\tTime 0.527 (0.582)\tLoss 0.4710 (0.4360)\t\n",
      "Epoch: [2] [30/500]\tTime 0.581 (0.579)\tLoss 0.3623 (0.4276)\t\n",
      "Epoch: [2] [35/500]\tTime 0.541 (0.574)\tLoss 0.4689 (0.4238)\t\n",
      "Epoch: [2] [40/500]\tTime 0.538 (0.572)\tLoss 0.5245 (0.4233)\t\n",
      "Epoch: [2] [45/500]\tTime 0.541 (0.569)\tLoss 0.4073 (0.4342)\t\n",
      "Epoch: [2] [50/500]\tTime 0.575 (0.567)\tLoss 0.5020 (0.4279)\t\n",
      "Epoch: [2] [55/500]\tTime 0.547 (0.566)\tLoss 0.4860 (0.4325)\t\n",
      "Epoch: [2] [60/500]\tTime 0.528 (0.564)\tLoss 0.4631 (0.4326)\t\n",
      "Epoch: [2] [65/500]\tTime 0.578 (0.563)\tLoss 0.3462 (0.4317)\t\n",
      "Epoch: [2] [70/500]\tTime 0.571 (0.563)\tLoss 0.3928 (0.4323)\t\n",
      "Epoch: [2] [75/500]\tTime 0.540 (0.561)\tLoss 0.5541 (0.4335)\t\n",
      "Epoch: [2] [80/500]\tTime 0.540 (0.561)\tLoss 0.5249 (0.4341)\t\n",
      "Epoch: [2] [85/500]\tTime 0.553 (0.560)\tLoss 0.5080 (0.4322)\t\n",
      "Epoch: [2] [90/500]\tTime 0.522 (0.560)\tLoss 0.3616 (0.4305)\t\n",
      "Epoch: [2] [95/500]\tTime 0.544 (0.559)\tLoss 0.3241 (0.4271)\t\n",
      "Epoch: [2] [100/500]\tTime 0.546 (0.559)\tLoss 0.4250 (0.4258)\t\n",
      "Epoch: [2] [105/500]\tTime 0.551 (0.560)\tLoss 0.4179 (0.4246)\t\n",
      "Epoch: [2] [110/500]\tTime 0.530 (0.559)\tLoss 0.5479 (0.4256)\t\n",
      "Epoch: [2] [115/500]\tTime 0.548 (0.558)\tLoss 0.5627 (0.4258)\t\n",
      "Epoch: [2] [120/500]\tTime 0.524 (0.558)\tLoss 0.3206 (0.4270)\t\n",
      "Epoch: [2] [125/500]\tTime 0.573 (0.558)\tLoss 0.5055 (0.4271)\t\n",
      "Epoch: [2] [130/500]\tTime 0.522 (0.557)\tLoss 0.4060 (0.4276)\t\n",
      "Epoch: [2] [135/500]\tTime 0.548 (0.557)\tLoss 0.4624 (0.4296)\t\n",
      "Epoch: [2] [140/500]\tTime 0.579 (0.557)\tLoss 0.3011 (0.4292)\t\n",
      "Epoch: [2] [145/500]\tTime 0.560 (0.556)\tLoss 0.2323 (0.4274)\t\n",
      "Epoch: [2] [150/500]\tTime 0.529 (0.556)\tLoss 0.4816 (0.4265)\t\n",
      "Epoch: [2] [155/500]\tTime 0.539 (0.555)\tLoss 0.3354 (0.4278)\t\n",
      "Epoch: [2] [160/500]\tTime 0.521 (0.555)\tLoss 0.4222 (0.4272)\t\n",
      "Epoch: [2] [165/500]\tTime 0.539 (0.555)\tLoss 0.4073 (0.4284)\t\n",
      "Epoch: [2] [170/500]\tTime 0.543 (0.555)\tLoss 0.2632 (0.4271)\t\n",
      "Epoch: [2] [175/500]\tTime 0.563 (0.554)\tLoss 0.4934 (0.4291)\t\n",
      "Epoch: [2] [180/500]\tTime 0.561 (0.554)\tLoss 0.4632 (0.4299)\t\n",
      "Epoch: [2] [185/500]\tTime 0.530 (0.554)\tLoss 0.4121 (0.4304)\t\n",
      "Epoch: [2] [190/500]\tTime 0.522 (0.553)\tLoss 0.4205 (0.4311)\t\n",
      "Epoch: [2] [195/500]\tTime 0.522 (0.553)\tLoss 0.4296 (0.4316)\t\n",
      "Epoch: [2] [200/500]\tTime 0.557 (0.553)\tLoss 0.6298 (0.4320)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [2] [205/500]\tTime 0.545 (0.553)\tLoss 0.4991 (0.4323)\t\n",
      "Epoch: [2] [210/500]\tTime 0.524 (0.553)\tLoss 0.4777 (0.4333)\t\n",
      "Epoch: [2] [215/500]\tTime 0.593 (0.553)\tLoss 0.5401 (0.4337)\t\n",
      "Epoch: [2] [220/500]\tTime 0.524 (0.552)\tLoss 0.3926 (0.4344)\t\n",
      "Epoch: [2] [225/500]\tTime 0.547 (0.552)\tLoss 0.5058 (0.4371)\t\n",
      "Epoch: [2] [230/500]\tTime 0.534 (0.552)\tLoss 0.2215 (0.4358)\t\n",
      "Epoch: [2] [235/500]\tTime 0.529 (0.552)\tLoss 0.3023 (0.4340)\t\n",
      "Epoch: [2] [240/500]\tTime 0.554 (0.552)\tLoss 0.4488 (0.4351)\t\n",
      "Epoch: [2] [245/500]\tTime 0.561 (0.552)\tLoss 0.5049 (0.4368)\t\n",
      "Epoch: [2] [250/500]\tTime 0.542 (0.552)\tLoss 0.3994 (0.4364)\t\n",
      "Epoch: [2] [255/500]\tTime 0.574 (0.552)\tLoss 0.6342 (0.4371)\t\n",
      "Epoch: [2] [260/500]\tTime 0.545 (0.552)\tLoss 0.3604 (0.4375)\t\n",
      "Epoch: [2] [265/500]\tTime 0.549 (0.552)\tLoss 0.5022 (0.4378)\t\n",
      "Epoch: [2] [270/500]\tTime 0.576 (0.552)\tLoss 0.6273 (0.4396)\t\n",
      "Epoch: [2] [275/500]\tTime 0.720 (0.554)\tLoss 0.4676 (0.4398)\t\n",
      "Epoch: [2] [280/500]\tTime 0.639 (0.557)\tLoss 0.5912 (0.4407)\t\n",
      "Epoch: [2] [285/500]\tTime 0.703 (0.559)\tLoss 0.4765 (0.4403)\t\n",
      "Epoch: [2] [290/500]\tTime 0.624 (0.560)\tLoss 0.3622 (0.4398)\t\n",
      "Epoch: [2] [295/500]\tTime 0.652 (0.560)\tLoss 0.7462 (0.4408)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2] [300/500]\tTime 0.567 (0.562)\tLoss 0.5585 (0.4407)\t\n",
      "Epoch: [2] [305/500]\tTime 0.591 (0.562)\tLoss 0.4690 (0.4404)\t\n",
      "Epoch: [2] [310/500]\tTime 0.561 (0.562)\tLoss 0.5218 (0.4404)\t\n",
      "Epoch: [2] [315/500]\tTime 0.545 (0.562)\tLoss 0.4070 (0.4409)\t\n",
      "Epoch: [2] [320/500]\tTime 0.532 (0.561)\tLoss 0.4647 (0.4416)\t\n",
      "Epoch: [2] [325/500]\tTime 0.532 (0.561)\tLoss 0.4460 (0.4418)\t\n",
      "Epoch: [2] [330/500]\tTime 0.549 (0.561)\tLoss 0.3226 (0.4413)\t\n",
      "Epoch: [2] [335/500]\tTime 0.528 (0.561)\tLoss 0.3429 (0.4413)\t\n",
      "Epoch: [2] [340/500]\tTime 0.543 (0.561)\tLoss 0.5324 (0.4425)\t\n",
      "Epoch: [2] [345/500]\tTime 0.544 (0.561)\tLoss 0.5539 (0.4438)\t\n",
      "Epoch: [2] [350/500]\tTime 0.597 (0.561)\tLoss 0.5231 (0.4440)\t\n",
      "Epoch: [2] [355/500]\tTime 0.577 (0.560)\tLoss 0.3760 (0.4442)\t\n",
      "Epoch: [2] [360/500]\tTime 0.566 (0.560)\tLoss 0.3988 (0.4438)\t\n",
      "Epoch: [2] [365/500]\tTime 0.553 (0.560)\tLoss 0.3536 (0.4440)\t\n",
      "Epoch: [2] [370/500]\tTime 0.531 (0.560)\tLoss 0.3266 (0.4441)\t\n",
      "Epoch: [2] [375/500]\tTime 0.548 (0.560)\tLoss 0.4939 (0.4441)\t\n",
      "Epoch: [2] [380/500]\tTime 0.564 (0.560)\tLoss 0.5739 (0.4448)\t\n",
      "Epoch: [2] [385/500]\tTime 0.531 (0.560)\tLoss 0.5375 (0.4457)\t\n",
      "Epoch: [2] [390/500]\tTime 0.529 (0.560)\tLoss 0.4957 (0.4461)\t\n",
      "Epoch: [2] [395/500]\tTime 0.543 (0.560)\tLoss 0.5138 (0.4473)\t\n",
      "Epoch: [2] [400/500]\tTime 0.575 (0.560)\tLoss 0.5675 (0.4478)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [2] [405/500]\tTime 0.548 (0.560)\tLoss 0.3604 (0.4484)\t\n",
      "Epoch: [2] [410/500]\tTime 0.533 (0.560)\tLoss 0.3945 (0.4481)\t\n",
      "Epoch: [2] [415/500]\tTime 0.547 (0.560)\tLoss 0.5797 (0.4493)\t\n",
      "Epoch: [2] [420/500]\tTime 0.545 (0.560)\tLoss 0.5744 (0.4497)\t\n",
      "Epoch: [2] [425/500]\tTime 0.542 (0.559)\tLoss 0.5140 (0.4501)\t\n",
      "Epoch: [2] [430/500]\tTime 0.540 (0.559)\tLoss 0.3483 (0.4504)\t\n",
      "Epoch: [2] [435/500]\tTime 0.558 (0.559)\tLoss 0.3625 (0.4502)\t\n",
      "Epoch: [2] [440/500]\tTime 0.566 (0.559)\tLoss 0.4424 (0.4502)\t\n",
      "Epoch: [2] [445/500]\tTime 0.544 (0.559)\tLoss 0.6305 (0.4511)\t\n",
      "Epoch: [2] [450/500]\tTime 0.613 (0.559)\tLoss 0.6404 (0.4520)\t\n",
      "Epoch: [2] [455/500]\tTime 0.548 (0.559)\tLoss 0.5095 (0.4522)\t\n",
      "Epoch: [2] [460/500]\tTime 0.524 (0.558)\tLoss 0.5199 (0.4523)\t\n",
      "Epoch: [2] [465/500]\tTime 0.539 (0.558)\tLoss 0.5078 (0.4523)\t\n",
      "Epoch: [2] [470/500]\tTime 0.567 (0.558)\tLoss 0.5789 (0.4526)\t\n",
      "Epoch: [2] [475/500]\tTime 0.540 (0.558)\tLoss 0.3743 (0.4522)\t\n",
      "Epoch: [2] [480/500]\tTime 0.563 (0.558)\tLoss 0.4775 (0.4530)\t\n",
      "Epoch: [2] [485/500]\tTime 0.528 (0.558)\tLoss 0.4627 (0.4530)\t\n",
      "Epoch: [2] [490/500]\tTime 0.586 (0.558)\tLoss 0.4292 (0.4528)\t\n",
      "Epoch: [2] [495/500]\tTime 0.545 (0.558)\tLoss 0.4521 (0.4527)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [3] [0/500]\tTime 0.566 (0.566)\tLoss 0.2712 (0.2712)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [3] [5/500]\tTime 0.545 (0.550)\tLoss 0.1614 (0.2290)\t\n",
      "Epoch: [3] [10/500]\tTime 0.560 (0.548)\tLoss 0.1878 (0.2179)\t\n",
      "Epoch: [3] [15/500]\tTime 0.547 (0.547)\tLoss 0.1843 (0.2190)\t\n",
      "Epoch: [3] [20/500]\tTime 0.539 (0.545)\tLoss 0.2834 (0.2183)\t\n",
      "Epoch: [3] [25/500]\tTime 0.555 (0.547)\tLoss 0.1608 (0.2168)\t\n",
      "Epoch: [3] [30/500]\tTime 0.522 (0.545)\tLoss 0.0967 (0.2142)\t\n",
      "Epoch: [3] [35/500]\tTime 0.532 (0.546)\tLoss 0.2000 (0.2171)\t\n",
      "Epoch: [3] [40/500]\tTime 0.528 (0.546)\tLoss 0.0658 (0.2143)\t\n",
      "Epoch: [3] [45/500]\tTime 0.545 (0.546)\tLoss 0.1574 (0.2158)\t\n",
      "Epoch: [3] [50/500]\tTime 0.578 (0.548)\tLoss 0.1835 (0.2155)\t\n",
      "Epoch: [3] [55/500]\tTime 0.521 (0.547)\tLoss 0.3590 (0.2160)\t\n",
      "Epoch: [3] [60/500]\tTime 0.540 (0.546)\tLoss 0.2106 (0.2134)\t\n",
      "Epoch: [3] [65/500]\tTime 0.523 (0.546)\tLoss 0.2079 (0.2153)\t\n",
      "Epoch: [3] [70/500]\tTime 0.530 (0.546)\tLoss 0.2203 (0.2185)\t\n",
      "Epoch: [3] [75/500]\tTime 0.529 (0.545)\tLoss 0.1282 (0.2169)\t\n",
      "Epoch: [3] [80/500]\tTime 0.531 (0.546)\tLoss 0.1477 (0.2125)\t\n",
      "Epoch: [3] [85/500]\tTime 0.528 (0.550)\tLoss 0.3003 (0.2128)\t\n",
      "Epoch: [3] [90/500]\tTime 0.643 (0.551)\tLoss 0.2304 (0.2127)\t\n",
      "Epoch: [3] [95/500]\tTime 0.527 (0.552)\tLoss 0.3381 (0.2166)\t\n",
      "Epoch: [3] [100/500]\tTime 0.562 (0.552)\tLoss 0.2797 (0.2163)\t\n",
      "Epoch: [3] [105/500]\tTime 0.628 (0.553)\tLoss 0.3492 (0.2200)\t\n",
      "Epoch: [3] [110/500]\tTime 0.546 (0.554)\tLoss 0.3197 (0.2204)\t\n",
      "Epoch: [3] [115/500]\tTime 0.532 (0.554)\tLoss 0.2023 (0.2197)\t\n",
      "Epoch: [3] [120/500]\tTime 0.539 (0.553)\tLoss 0.3830 (0.2189)\t\n",
      "Epoch: [3] [125/500]\tTime 0.666 (0.554)\tLoss 0.1824 (0.2183)\t\n",
      "Epoch: [3] [130/500]\tTime 0.538 (0.554)\tLoss 0.2269 (0.2171)\t\n",
      "Epoch: [3] [135/500]\tTime 0.540 (0.554)\tLoss 0.1285 (0.2154)\t\n",
      "Epoch: [3] [140/500]\tTime 0.618 (0.554)\tLoss 0.2126 (0.2150)\t\n",
      "Epoch: [3] [145/500]\tTime 0.594 (0.556)\tLoss 0.1256 (0.2137)\t\n",
      "Epoch: [3] [150/500]\tTime 0.523 (0.556)\tLoss 0.2014 (0.2145)\t\n",
      "Epoch: [3] [155/500]\tTime 0.562 (0.556)\tLoss 0.2506 (0.2145)\t\n",
      "Epoch: [3] [160/500]\tTime 0.583 (0.556)\tLoss 0.2134 (0.2146)\t\n",
      "Epoch: [3] [165/500]\tTime 0.563 (0.555)\tLoss 0.3363 (0.2156)\t\n",
      "Epoch: [3] [170/500]\tTime 0.566 (0.555)\tLoss 0.1786 (0.2156)\t\n",
      "Epoch: [3] [175/500]\tTime 0.541 (0.555)\tLoss 0.2189 (0.2154)\t\n",
      "Epoch: [3] [180/500]\tTime 0.600 (0.557)\tLoss 0.2765 (0.2164)\t\n",
      "Epoch: [3] [185/500]\tTime 0.549 (0.558)\tLoss 0.2630 (0.2171)\t\n",
      "Epoch: [3] [190/500]\tTime 0.551 (0.557)\tLoss 0.3267 (0.2180)\t\n",
      "Epoch: [3] [195/500]\tTime 0.545 (0.557)\tLoss 0.1403 (0.2176)\t\n",
      "Epoch: [3] [200/500]\tTime 0.540 (0.557)\tLoss 0.2467 (0.2173)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [3] [205/500]\tTime 0.528 (0.557)\tLoss 0.2441 (0.2164)\t\n",
      "Epoch: [3] [210/500]\tTime 0.545 (0.557)\tLoss 0.2814 (0.2166)\t\n",
      "Epoch: [3] [215/500]\tTime 0.544 (0.557)\tLoss 0.2593 (0.2173)\t\n",
      "Epoch: [3] [220/500]\tTime 0.563 (0.556)\tLoss 0.1971 (0.2173)\t\n",
      "Epoch: [3] [225/500]\tTime 0.565 (0.557)\tLoss 0.1037 (0.2177)\t\n",
      "Epoch: [3] [230/500]\tTime 0.545 (0.557)\tLoss 0.2294 (0.2178)\t\n",
      "Epoch: [3] [235/500]\tTime 0.525 (0.556)\tLoss 0.2394 (0.2179)\t\n",
      "Epoch: [3] [240/500]\tTime 0.539 (0.556)\tLoss 0.1959 (0.2172)\t\n",
      "Epoch: [3] [245/500]\tTime 0.529 (0.556)\tLoss 0.0797 (0.2175)\t\n",
      "Epoch: [3] [250/500]\tTime 0.531 (0.555)\tLoss 0.1156 (0.2170)\t\n",
      "Epoch: [3] [255/500]\tTime 0.576 (0.555)\tLoss 0.2537 (0.2171)\t\n",
      "Epoch: [3] [260/500]\tTime 0.571 (0.555)\tLoss 0.1563 (0.2169)\t\n",
      "Epoch: [3] [265/500]\tTime 0.549 (0.556)\tLoss 0.2095 (0.2172)\t\n",
      "Epoch: [3] [270/500]\tTime 0.570 (0.556)\tLoss 0.2123 (0.2173)\t\n",
      "Epoch: [3] [275/500]\tTime 0.542 (0.556)\tLoss 0.2078 (0.2182)\t\n",
      "Epoch: [3] [280/500]\tTime 0.593 (0.556)\tLoss 0.3079 (0.2180)\t\n",
      "Epoch: [3] [285/500]\tTime 0.611 (0.556)\tLoss 0.2496 (0.2185)\t\n",
      "Epoch: [3] [290/500]\tTime 0.534 (0.556)\tLoss 0.2105 (0.2190)\t\n",
      "Epoch: [3] [295/500]\tTime 0.548 (0.556)\tLoss 0.1769 (0.2191)\t\n",
      "Epoch: [3] [300/500]\tTime 0.536 (0.555)\tLoss 0.3307 (0.2197)\t\n",
      "Epoch: [3] [305/500]\tTime 0.551 (0.555)\tLoss 0.2021 (0.2208)\t\n",
      "Epoch: [3] [310/500]\tTime 0.548 (0.555)\tLoss 0.2457 (0.2207)\t\n",
      "Epoch: [3] [315/500]\tTime 0.566 (0.556)\tLoss 0.2158 (0.2206)\t\n",
      "Epoch: [3] [320/500]\tTime 0.550 (0.556)\tLoss 0.1779 (0.2204)\t\n",
      "Epoch: [3] [325/500]\tTime 0.558 (0.556)\tLoss 0.3264 (0.2212)\t\n",
      "Epoch: [3] [330/500]\tTime 0.543 (0.555)\tLoss 0.1184 (0.2211)\t\n",
      "Epoch: [3] [335/500]\tTime 0.542 (0.555)\tLoss 0.2624 (0.2213)\t\n",
      "Epoch: [3] [340/500]\tTime 0.525 (0.555)\tLoss 0.2241 (0.2205)\t\n",
      "Epoch: [3] [345/500]\tTime 0.548 (0.555)\tLoss 0.1573 (0.2206)\t\n",
      "Epoch: [3] [350/500]\tTime 0.533 (0.555)\tLoss 0.2827 (0.2209)\t\n",
      "Epoch: [3] [355/500]\tTime 0.533 (0.555)\tLoss 0.3364 (0.2211)\t\n",
      "Epoch: [3] [360/500]\tTime 0.561 (0.555)\tLoss 0.1215 (0.2209)\t\n",
      "Epoch: [3] [365/500]\tTime 0.615 (0.555)\tLoss 0.1941 (0.2212)\t\n",
      "Epoch: [3] [370/500]\tTime 0.559 (0.555)\tLoss 0.1899 (0.2212)\t\n",
      "Epoch: [3] [375/500]\tTime 0.543 (0.555)\tLoss 0.1789 (0.2220)\t\n",
      "Epoch: [3] [380/500]\tTime 0.542 (0.555)\tLoss 0.2474 (0.2223)\t\n",
      "Epoch: [3] [385/500]\tTime 0.578 (0.555)\tLoss 0.2237 (0.2231)\t\n",
      "Epoch: [3] [390/500]\tTime 0.572 (0.555)\tLoss 0.2753 (0.2238)\t\n",
      "Epoch: [3] [395/500]\tTime 0.555 (0.555)\tLoss 0.2671 (0.2245)\t\n",
      "Epoch: [3] [400/500]\tTime 0.563 (0.555)\tLoss 0.1434 (0.2255)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [3] [405/500]\tTime 0.567 (0.555)\tLoss 0.2547 (0.2255)\t\n",
      "Epoch: [3] [410/500]\tTime 0.556 (0.555)\tLoss 0.3113 (0.2261)\t\n",
      "Epoch: [3] [415/500]\tTime 0.544 (0.555)\tLoss 0.3906 (0.2274)\t\n",
      "Epoch: [3] [420/500]\tTime 0.553 (0.555)\tLoss 0.2789 (0.2280)\t\n",
      "Epoch: [3] [425/500]\tTime 0.513 (0.555)\tLoss 0.2373 (0.2280)\t\n",
      "Epoch: [3] [430/500]\tTime 0.629 (0.555)\tLoss 0.1726 (0.2282)\t\n",
      "Epoch: [3] [435/500]\tTime 0.582 (0.556)\tLoss 0.2502 (0.2278)\t\n",
      "Epoch: [3] [440/500]\tTime 0.541 (0.556)\tLoss 0.3494 (0.2284)\t\n",
      "Epoch: [3] [445/500]\tTime 0.524 (0.556)\tLoss 0.3424 (0.2287)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3] [450/500]\tTime 0.552 (0.556)\tLoss 0.3304 (0.2292)\t\n",
      "Epoch: [3] [455/500]\tTime 0.547 (0.556)\tLoss 0.3796 (0.2297)\t\n",
      "Epoch: [3] [460/500]\tTime 0.567 (0.556)\tLoss 0.3220 (0.2309)\t\n",
      "Epoch: [3] [465/500]\tTime 0.548 (0.556)\tLoss 0.1800 (0.2311)\t\n",
      "Epoch: [3] [470/500]\tTime 0.530 (0.556)\tLoss 0.1930 (0.2316)\t\n",
      "Epoch: [3] [475/500]\tTime 0.522 (0.556)\tLoss 0.2083 (0.2317)\t\n",
      "Epoch: [3] [480/500]\tTime 0.540 (0.556)\tLoss 0.4096 (0.2320)\t\n",
      "Epoch: [3] [485/500]\tTime 0.557 (0.556)\tLoss 0.2083 (0.2319)\t\n",
      "Epoch: [3] [490/500]\tTime 0.556 (0.556)\tLoss 0.2753 (0.2322)\t\n",
      "Epoch: [3] [495/500]\tTime 0.580 (0.556)\tLoss 0.3669 (0.2329)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [4] [0/500]\tTime 0.552 (0.552)\tLoss 0.0983 (0.0983)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [4] [5/500]\tTime 0.543 (0.544)\tLoss 0.1337 (0.1213)\t\n",
      "Epoch: [4] [10/500]\tTime 0.545 (0.546)\tLoss 0.1755 (0.1527)\t\n",
      "Epoch: [4] [15/500]\tTime 0.562 (0.552)\tLoss 0.1065 (0.1481)\t\n",
      "Epoch: [4] [20/500]\tTime 0.530 (0.549)\tLoss 0.1268 (0.1572)\t\n",
      "Epoch: [4] [25/500]\tTime 0.528 (0.548)\tLoss 0.1963 (0.1546)\t\n",
      "Epoch: [4] [30/500]\tTime 0.543 (0.547)\tLoss 0.0884 (0.1485)\t\n",
      "Epoch: [4] [35/500]\tTime 0.523 (0.548)\tLoss 0.1053 (0.1445)\t\n",
      "Epoch: [4] [40/500]\tTime 0.538 (0.547)\tLoss 0.2547 (0.1455)\t\n",
      "Epoch: [4] [45/500]\tTime 0.522 (0.548)\tLoss 0.1250 (0.1425)\t\n",
      "Epoch: [4] [50/500]\tTime 0.613 (0.550)\tLoss 0.1149 (0.1404)\t\n",
      "Epoch: [4] [55/500]\tTime 0.548 (0.549)\tLoss 0.1286 (0.1403)\t\n",
      "Epoch: [4] [60/500]\tTime 0.545 (0.550)\tLoss 0.1573 (0.1411)\t\n",
      "Epoch: [4] [65/500]\tTime 0.544 (0.550)\tLoss 0.1869 (0.1408)\t\n",
      "Epoch: [4] [70/500]\tTime 0.527 (0.549)\tLoss 0.1589 (0.1418)\t\n",
      "Epoch: [4] [75/500]\tTime 0.539 (0.549)\tLoss 0.1867 (0.1419)\t\n",
      "Epoch: [4] [80/500]\tTime 0.522 (0.549)\tLoss 0.1556 (0.1418)\t\n",
      "Epoch: [4] [85/500]\tTime 0.540 (0.549)\tLoss 0.1271 (0.1422)\t\n",
      "Epoch: [4] [90/500]\tTime 0.565 (0.549)\tLoss 0.0369 (0.1397)\t\n",
      "Epoch: [4] [95/500]\tTime 0.549 (0.549)\tLoss 0.0752 (0.1386)\t\n",
      "Epoch: [4] [100/500]\tTime 0.563 (0.549)\tLoss 0.1918 (0.1404)\t\n",
      "Epoch: [4] [105/500]\tTime 0.635 (0.550)\tLoss 0.0903 (0.1394)\t\n",
      "Epoch: [4] [110/500]\tTime 0.541 (0.549)\tLoss 0.0968 (0.1384)\t\n",
      "Epoch: [4] [115/500]\tTime 0.523 (0.548)\tLoss 0.2734 (0.1387)\t\n",
      "Epoch: [4] [120/500]\tTime 0.556 (0.549)\tLoss 0.1298 (0.1373)\t\n",
      "Epoch: [4] [125/500]\tTime 0.545 (0.548)\tLoss 0.1538 (0.1382)\t\n",
      "Epoch: [4] [130/500]\tTime 0.531 (0.548)\tLoss 0.1501 (0.1390)\t\n",
      "Epoch: [4] [135/500]\tTime 0.543 (0.548)\tLoss 0.1135 (0.1380)\t\n",
      "Epoch: [4] [140/500]\tTime 0.528 (0.548)\tLoss 0.1287 (0.1381)\t\n",
      "Epoch: [4] [145/500]\tTime 0.594 (0.548)\tLoss 0.1110 (0.1377)\t\n",
      "Epoch: [4] [150/500]\tTime 0.521 (0.548)\tLoss 0.0558 (0.1379)\t\n",
      "Epoch: [4] [155/500]\tTime 0.554 (0.548)\tLoss 0.0915 (0.1376)\t\n",
      "Epoch: [4] [160/500]\tTime 0.547 (0.548)\tLoss 0.1562 (0.1381)\t\n",
      "Epoch: [4] [165/500]\tTime 0.546 (0.548)\tLoss 0.1738 (0.1376)\t\n",
      "Epoch: [4] [170/500]\tTime 0.528 (0.548)\tLoss 0.2323 (0.1378)\t\n",
      "Epoch: [4] [175/500]\tTime 0.530 (0.548)\tLoss 0.0737 (0.1386)\t\n",
      "Epoch: [4] [180/500]\tTime 0.529 (0.548)\tLoss 0.2289 (0.1384)\t\n",
      "Epoch: [4] [185/500]\tTime 0.540 (0.548)\tLoss 0.1697 (0.1381)\t\n",
      "Epoch: [4] [190/500]\tTime 0.524 (0.547)\tLoss 0.1016 (0.1370)\t\n",
      "Epoch: [4] [195/500]\tTime 0.546 (0.547)\tLoss 0.2062 (0.1372)\t\n",
      "Epoch: [4] [200/500]\tTime 0.532 (0.547)\tLoss 0.1247 (0.1367)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [4] [205/500]\tTime 0.540 (0.547)\tLoss 0.1283 (0.1367)\t\n",
      "Epoch: [4] [210/500]\tTime 0.559 (0.548)\tLoss 0.1096 (0.1364)\t\n",
      "Epoch: [4] [215/500]\tTime 0.542 (0.548)\tLoss 0.2006 (0.1358)\t\n",
      "Epoch: [4] [220/500]\tTime 0.526 (0.548)\tLoss 0.2584 (0.1370)\t\n",
      "Epoch: [4] [225/500]\tTime 0.551 (0.548)\tLoss 0.1174 (0.1371)\t\n",
      "Epoch: [4] [230/500]\tTime 0.531 (0.548)\tLoss 0.2014 (0.1382)\t\n",
      "Epoch: [4] [235/500]\tTime 0.651 (0.549)\tLoss 0.0824 (0.1386)\t\n",
      "Epoch: [4] [240/500]\tTime 0.581 (0.550)\tLoss 0.1013 (0.1376)\t\n",
      "Epoch: [4] [245/500]\tTime 0.605 (0.552)\tLoss 0.1865 (0.1377)\t\n",
      "Epoch: [4] [250/500]\tTime 0.564 (0.552)\tLoss 0.1290 (0.1380)\t\n",
      "Epoch: [4] [255/500]\tTime 0.548 (0.552)\tLoss 0.1014 (0.1385)\t\n",
      "Epoch: [4] [260/500]\tTime 0.715 (0.553)\tLoss 0.1305 (0.1385)\t\n",
      "Epoch: [4] [265/500]\tTime 0.570 (0.553)\tLoss 0.1664 (0.1392)\t\n",
      "Epoch: [4] [270/500]\tTime 0.567 (0.554)\tLoss 0.1784 (0.1387)\t\n",
      "Epoch: [4] [275/500]\tTime 0.569 (0.554)\tLoss 0.0839 (0.1388)\t\n",
      "Epoch: [4] [280/500]\tTime 0.536 (0.554)\tLoss 0.2637 (0.1399)\t\n",
      "Epoch: [4] [285/500]\tTime 0.553 (0.554)\tLoss 0.1832 (0.1402)\t\n",
      "Epoch: [4] [290/500]\tTime 0.552 (0.555)\tLoss 0.0692 (0.1403)\t\n",
      "Epoch: [4] [295/500]\tTime 0.535 (0.555)\tLoss 0.2024 (0.1408)\t\n",
      "Epoch: [4] [300/500]\tTime 0.554 (0.555)\tLoss 0.2909 (0.1411)\t\n",
      "Epoch: [4] [305/500]\tTime 0.553 (0.556)\tLoss 0.3209 (0.1414)\t\n",
      "Epoch: [4] [310/500]\tTime 0.570 (0.556)\tLoss 0.0601 (0.1411)\t\n",
      "Epoch: [4] [315/500]\tTime 0.535 (0.556)\tLoss 0.0678 (0.1409)\t\n",
      "Epoch: [4] [320/500]\tTime 0.537 (0.556)\tLoss 0.1172 (0.1414)\t\n",
      "Epoch: [4] [325/500]\tTime 0.536 (0.557)\tLoss 0.0754 (0.1410)\t\n",
      "Epoch: [4] [330/500]\tTime 0.587 (0.557)\tLoss 0.3441 (0.1415)\t\n",
      "Epoch: [4] [335/500]\tTime 0.550 (0.557)\tLoss 0.3539 (0.1422)\t\n",
      "Epoch: [4] [340/500]\tTime 0.537 (0.557)\tLoss 0.2439 (0.1430)\t\n",
      "Epoch: [4] [345/500]\tTime 0.536 (0.557)\tLoss 0.2526 (0.1433)\t\n",
      "Epoch: [4] [350/500]\tTime 0.563 (0.557)\tLoss 0.1732 (0.1433)\t\n",
      "Epoch: [4] [355/500]\tTime 0.581 (0.557)\tLoss 0.1291 (0.1431)\t\n",
      "Epoch: [4] [360/500]\tTime 0.562 (0.557)\tLoss 0.1717 (0.1437)\t\n",
      "Epoch: [4] [365/500]\tTime 0.828 (0.559)\tLoss 0.1435 (0.1444)\t\n",
      "Epoch: [4] [370/500]\tTime 0.661 (0.560)\tLoss 0.1841 (0.1446)\t\n",
      "Epoch: [4] [375/500]\tTime 0.537 (0.561)\tLoss 0.1232 (0.1452)\t\n",
      "Epoch: [4] [380/500]\tTime 0.546 (0.562)\tLoss 0.2173 (0.1456)\t\n",
      "Epoch: [4] [385/500]\tTime 0.542 (0.562)\tLoss 0.1815 (0.1459)\t\n",
      "Epoch: [4] [390/500]\tTime 0.554 (0.561)\tLoss 0.1783 (0.1459)\t\n",
      "Epoch: [4] [395/500]\tTime 0.573 (0.561)\tLoss 0.1946 (0.1463)\t\n",
      "Epoch: [4] [400/500]\tTime 0.555 (0.562)\tLoss 0.2355 (0.1466)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [4] [405/500]\tTime 0.547 (0.562)\tLoss 0.0942 (0.1472)\t\n",
      "Epoch: [4] [410/500]\tTime 0.510 (0.562)\tLoss 0.2192 (0.1476)\t\n",
      "Epoch: [4] [415/500]\tTime 0.544 (0.561)\tLoss 0.1799 (0.1490)\t\n",
      "Epoch: [4] [420/500]\tTime 0.543 (0.561)\tLoss 0.1695 (0.1488)\t\n",
      "Epoch: [4] [425/500]\tTime 0.568 (0.561)\tLoss 0.1090 (0.1491)\t\n",
      "Epoch: [4] [430/500]\tTime 0.543 (0.561)\tLoss 0.0480 (0.1492)\t\n",
      "Epoch: [4] [435/500]\tTime 0.526 (0.562)\tLoss 0.2536 (0.1497)\t\n",
      "Epoch: [4] [440/500]\tTime 0.552 (0.561)\tLoss 0.2210 (0.1499)\t\n",
      "Epoch: [4] [445/500]\tTime 0.538 (0.561)\tLoss 0.1892 (0.1501)\t\n",
      "Epoch: [4] [450/500]\tTime 0.568 (0.561)\tLoss 0.1477 (0.1501)\t\n",
      "Epoch: [4] [455/500]\tTime 0.618 (0.561)\tLoss 0.1346 (0.1503)\t\n",
      "Epoch: [4] [460/500]\tTime 0.578 (0.561)\tLoss 0.1143 (0.1501)\t\n",
      "Epoch: [4] [465/500]\tTime 0.526 (0.561)\tLoss 0.1184 (0.1507)\t\n",
      "Epoch: [4] [470/500]\tTime 0.542 (0.561)\tLoss 0.2014 (0.1505)\t\n",
      "Epoch: [4] [475/500]\tTime 0.541 (0.561)\tLoss 0.2143 (0.1506)\t\n",
      "Epoch: [4] [480/500]\tTime 0.660 (0.561)\tLoss 0.2202 (0.1510)\t\n",
      "Epoch: [4] [485/500]\tTime 0.539 (0.561)\tLoss 0.2527 (0.1514)\t\n",
      "Epoch: [4] [490/500]\tTime 0.559 (0.561)\tLoss 0.1266 (0.1518)\t\n",
      "Epoch: [4] [495/500]\tTime 0.551 (0.560)\tLoss 0.2877 (0.1529)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [5] [0/500]\tTime 0.560 (0.560)\tLoss 0.0632 (0.0632)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [5] [5/500]\tTime 0.706 (0.584)\tLoss 0.0563 (0.1055)\t\n",
      "Epoch: [5] [10/500]\tTime 0.539 (0.578)\tLoss 0.0648 (0.0858)\t\n",
      "Epoch: [5] [15/500]\tTime 0.539 (0.572)\tLoss 0.0858 (0.0863)\t\n",
      "Epoch: [5] [20/500]\tTime 0.559 (0.581)\tLoss 0.0988 (0.0873)\t\n",
      "Epoch: [5] [25/500]\tTime 0.710 (0.589)\tLoss 0.1195 (0.0959)\t\n",
      "Epoch: [5] [30/500]\tTime 0.556 (0.582)\tLoss 0.2310 (0.1022)\t\n",
      "Epoch: [5] [35/500]\tTime 0.524 (0.576)\tLoss 0.0447 (0.0995)\t\n",
      "Epoch: [5] [40/500]\tTime 0.538 (0.573)\tLoss 0.0945 (0.1021)\t\n",
      "Epoch: [5] [45/500]\tTime 0.539 (0.570)\tLoss 0.1088 (0.1031)\t\n",
      "Epoch: [5] [50/500]\tTime 0.531 (0.567)\tLoss 0.1110 (0.0995)\t\n",
      "Epoch: [5] [55/500]\tTime 0.683 (0.568)\tLoss 0.0746 (0.1005)\t\n",
      "Epoch: [5] [60/500]\tTime 0.597 (0.567)\tLoss 0.1053 (0.1023)\t\n",
      "Epoch: [5] [65/500]\tTime 0.570 (0.571)\tLoss 0.0546 (0.1017)\t\n",
      "Epoch: [5] [70/500]\tTime 0.540 (0.569)\tLoss 0.1961 (0.1013)\t\n",
      "Epoch: [5] [75/500]\tTime 0.541 (0.567)\tLoss 0.1777 (0.1009)\t\n",
      "Epoch: [5] [80/500]\tTime 0.552 (0.568)\tLoss 0.0505 (0.0987)\t\n",
      "Epoch: [5] [85/500]\tTime 0.551 (0.567)\tLoss 0.0953 (0.0997)\t\n",
      "Epoch: [5] [90/500]\tTime 0.568 (0.566)\tLoss 0.1664 (0.1015)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5] [95/500]\tTime 0.552 (0.567)\tLoss 0.1842 (0.1036)\t\n",
      "Epoch: [5] [100/500]\tTime 0.551 (0.567)\tLoss 0.1029 (0.1041)\t\n",
      "Epoch: [5] [105/500]\tTime 0.536 (0.567)\tLoss 0.0647 (0.1033)\t\n",
      "Epoch: [5] [110/500]\tTime 0.526 (0.566)\tLoss 0.1316 (0.1026)\t\n",
      "Epoch: [5] [115/500]\tTime 0.522 (0.565)\tLoss 0.0892 (0.1026)\t\n",
      "Epoch: [5] [120/500]\tTime 0.522 (0.564)\tLoss 0.0514 (0.1024)\t\n",
      "Epoch: [5] [125/500]\tTime 0.540 (0.564)\tLoss 0.0386 (0.1037)\t\n",
      "Epoch: [5] [130/500]\tTime 0.522 (0.565)\tLoss 0.1044 (0.1037)\t\n",
      "Epoch: [5] [135/500]\tTime 0.538 (0.564)\tLoss 0.0859 (0.1035)\t\n",
      "Epoch: [5] [140/500]\tTime 0.572 (0.563)\tLoss 0.2812 (0.1054)\t\n",
      "Epoch: [5] [145/500]\tTime 0.550 (0.565)\tLoss 0.1573 (0.1061)\t\n",
      "Epoch: [5] [150/500]\tTime 0.551 (0.565)\tLoss 0.1547 (0.1070)\t\n",
      "Epoch: [5] [155/500]\tTime 0.622 (0.566)\tLoss 0.0888 (0.1066)\t\n",
      "Epoch: [5] [160/500]\tTime 0.544 (0.567)\tLoss 0.1367 (0.1068)\t\n",
      "Epoch: [5] [165/500]\tTime 0.587 (0.568)\tLoss 0.1538 (0.1072)\t\n",
      "Epoch: [5] [170/500]\tTime 0.569 (0.573)\tLoss 0.1333 (0.1064)\t\n",
      "Epoch: [5] [175/500]\tTime 0.872 (0.583)\tLoss 0.0470 (0.1051)\t\n",
      "Epoch: [5] [180/500]\tTime 0.712 (0.583)\tLoss 0.0907 (0.1046)\t\n",
      "Epoch: [5] [185/500]\tTime 0.523 (0.583)\tLoss 0.1278 (0.1046)\t\n",
      "Epoch: [5] [190/500]\tTime 0.539 (0.582)\tLoss 0.1113 (0.1041)\t\n",
      "Epoch: [5] [195/500]\tTime 0.557 (0.582)\tLoss 0.1491 (0.1039)\t\n",
      "Epoch: [5] [200/500]\tTime 0.552 (0.581)\tLoss 0.0123 (0.1039)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [5] [205/500]\tTime 0.571 (0.581)\tLoss 0.0632 (0.1034)\t\n",
      "Epoch: [5] [210/500]\tTime 0.555 (0.580)\tLoss 0.1426 (0.1038)\t\n",
      "Epoch: [5] [215/500]\tTime 0.551 (0.580)\tLoss 0.3710 (0.1053)\t\n",
      "Epoch: [5] [220/500]\tTime 0.570 (0.579)\tLoss 0.0896 (0.1049)\t\n",
      "Epoch: [5] [225/500]\tTime 0.569 (0.579)\tLoss 0.0435 (0.1055)\t\n",
      "Epoch: [5] [230/500]\tTime 0.543 (0.578)\tLoss 0.0644 (0.1054)\t\n",
      "Epoch: [5] [235/500]\tTime 0.522 (0.578)\tLoss 0.1136 (0.1060)\t\n",
      "Epoch: [5] [240/500]\tTime 0.574 (0.578)\tLoss 0.1048 (0.1055)\t\n",
      "Epoch: [5] [245/500]\tTime 0.566 (0.577)\tLoss 0.1276 (0.1057)\t\n",
      "Epoch: [5] [250/500]\tTime 0.543 (0.576)\tLoss 0.0416 (0.1058)\t\n",
      "Epoch: [5] [255/500]\tTime 0.552 (0.576)\tLoss 0.0960 (0.1067)\t\n",
      "Epoch: [5] [260/500]\tTime 0.571 (0.576)\tLoss 0.0936 (0.1065)\t\n",
      "Epoch: [5] [265/500]\tTime 0.552 (0.576)\tLoss 0.2136 (0.1079)\t\n",
      "Epoch: [5] [270/500]\tTime 0.555 (0.576)\tLoss 0.0636 (0.1070)\t\n",
      "Epoch: [5] [275/500]\tTime 0.551 (0.576)\tLoss 0.1247 (0.1075)\t\n",
      "Epoch: [5] [280/500]\tTime 0.553 (0.576)\tLoss 0.1813 (0.1077)\t\n",
      "Epoch: [5] [285/500]\tTime 0.602 (0.576)\tLoss 0.1063 (0.1074)\t\n",
      "Epoch: [5] [290/500]\tTime 0.567 (0.576)\tLoss 0.1104 (0.1072)\t\n",
      "Epoch: [5] [295/500]\tTime 0.571 (0.576)\tLoss 0.0368 (0.1074)\t\n",
      "Epoch: [5] [300/500]\tTime 0.539 (0.576)\tLoss 0.1737 (0.1076)\t\n",
      "Epoch: [5] [305/500]\tTime 0.572 (0.575)\tLoss 0.1938 (0.1089)\t\n",
      "Epoch: [5] [310/500]\tTime 0.538 (0.575)\tLoss 0.1728 (0.1100)\t\n",
      "Epoch: [5] [315/500]\tTime 0.543 (0.574)\tLoss 0.0520 (0.1098)\t\n",
      "Epoch: [5] [320/500]\tTime 0.543 (0.574)\tLoss 0.1619 (0.1096)\t\n",
      "Epoch: [5] [325/500]\tTime 0.556 (0.575)\tLoss 0.1661 (0.1098)\t\n",
      "Epoch: [5] [330/500]\tTime 0.524 (0.574)\tLoss 0.2227 (0.1101)\t\n",
      "Epoch: [5] [335/500]\tTime 0.528 (0.574)\tLoss 0.0196 (0.1095)\t\n",
      "Epoch: [5] [340/500]\tTime 0.589 (0.574)\tLoss 0.1375 (0.1098)\t\n",
      "Epoch: [5] [345/500]\tTime 0.904 (0.577)\tLoss 0.0980 (0.1098)\t\n",
      "Epoch: [5] [350/500]\tTime 0.903 (0.580)\tLoss 0.1308 (0.1102)\t\n",
      "Epoch: [5] [355/500]\tTime 0.625 (0.581)\tLoss 0.0458 (0.1100)\t\n",
      "Epoch: [5] [360/500]\tTime 0.678 (0.583)\tLoss 0.1522 (0.1099)\t\n",
      "Epoch: [5] [365/500]\tTime 0.822 (0.585)\tLoss 0.1648 (0.1104)\t\n",
      "Epoch: [5] [370/500]\tTime 0.644 (0.585)\tLoss 0.0730 (0.1112)\t\n",
      "Epoch: [5] [375/500]\tTime 0.570 (0.585)\tLoss 0.2075 (0.1117)\t\n",
      "Epoch: [5] [380/500]\tTime 0.556 (0.585)\tLoss 0.1897 (0.1118)\t\n",
      "Epoch: [5] [385/500]\tTime 0.528 (0.586)\tLoss 0.1587 (0.1124)\t\n",
      "Epoch: [5] [390/500]\tTime 0.733 (0.588)\tLoss 0.0255 (0.1127)\t\n",
      "Epoch: [5] [395/500]\tTime 0.557 (0.588)\tLoss 0.1670 (0.1126)\t\n",
      "Epoch: [5] [400/500]\tTime 0.544 (0.588)\tLoss 0.1221 (0.1128)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [5] [405/500]\tTime 0.547 (0.588)\tLoss 0.0478 (0.1128)\t\n",
      "Epoch: [5] [410/500]\tTime 0.941 (0.590)\tLoss 0.1140 (0.1128)\t\n",
      "Epoch: [5] [415/500]\tTime 0.558 (0.591)\tLoss 0.1595 (0.1133)\t\n",
      "Epoch: [5] [420/500]\tTime 0.572 (0.592)\tLoss 0.0566 (0.1136)\t\n",
      "Epoch: [5] [425/500]\tTime 0.617 (0.593)\tLoss 0.1444 (0.1137)\t\n",
      "Epoch: [5] [430/500]\tTime 0.553 (0.593)\tLoss 0.2243 (0.1140)\t\n",
      "Epoch: [5] [435/500]\tTime 0.535 (0.592)\tLoss 0.1713 (0.1144)\t\n",
      "Epoch: [5] [440/500]\tTime 0.551 (0.592)\tLoss 0.1098 (0.1143)\t\n",
      "Epoch: [5] [445/500]\tTime 0.535 (0.591)\tLoss 0.1077 (0.1147)\t\n",
      "Epoch: [5] [450/500]\tTime 0.526 (0.591)\tLoss 0.1037 (0.1151)\t\n",
      "Epoch: [5] [455/500]\tTime 0.540 (0.591)\tLoss 0.2386 (0.1153)\t\n",
      "Epoch: [5] [460/500]\tTime 0.540 (0.590)\tLoss 0.1252 (0.1154)\t\n",
      "Epoch: [5] [465/500]\tTime 0.540 (0.590)\tLoss 0.1212 (0.1157)\t\n",
      "Epoch: [5] [470/500]\tTime 0.687 (0.590)\tLoss 0.2129 (0.1160)\t\n",
      "Epoch: [5] [475/500]\tTime 0.538 (0.590)\tLoss 0.2474 (0.1169)\t\n",
      "Epoch: [5] [480/500]\tTime 0.539 (0.589)\tLoss 0.0864 (0.1169)\t\n",
      "Epoch: [5] [485/500]\tTime 0.549 (0.589)\tLoss 0.0839 (0.1167)\t\n",
      "Epoch: [5] [490/500]\tTime 0.554 (0.589)\tLoss 0.2361 (0.1167)\t\n",
      "Epoch: [5] [495/500]\tTime 0.548 (0.589)\tLoss 0.1147 (0.1171)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [6] [0/500]\tTime 0.582 (0.582)\tLoss 0.1642 (0.1642)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [6] [5/500]\tTime 0.540 (0.568)\tLoss 0.1017 (0.0827)\t\n",
      "Epoch: [6] [10/500]\tTime 0.546 (0.561)\tLoss 0.1693 (0.1054)\t\n",
      "Epoch: [6] [15/500]\tTime 0.534 (0.562)\tLoss 0.0656 (0.0910)\t\n",
      "Epoch: [6] [20/500]\tTime 0.576 (0.561)\tLoss 0.0256 (0.0890)\t\n",
      "Epoch: [6] [25/500]\tTime 0.541 (0.561)\tLoss 0.0585 (0.0875)\t\n",
      "Epoch: [6] [30/500]\tTime 0.575 (0.560)\tLoss 0.0593 (0.0852)\t\n",
      "Epoch: [6] [35/500]\tTime 0.565 (0.560)\tLoss 0.0435 (0.0900)\t\n",
      "Epoch: [6] [40/500]\tTime 0.583 (0.563)\tLoss 0.0475 (0.0926)\t\n",
      "Epoch: [6] [45/500]\tTime 0.553 (0.562)\tLoss 0.0906 (0.0906)\t\n",
      "Epoch: [6] [50/500]\tTime 0.535 (0.563)\tLoss 0.1053 (0.0913)\t\n",
      "Epoch: [6] [55/500]\tTime 0.568 (0.561)\tLoss 0.0406 (0.0901)\t\n",
      "Epoch: [6] [60/500]\tTime 0.536 (0.560)\tLoss 0.0845 (0.0899)\t\n",
      "Epoch: [6] [65/500]\tTime 0.540 (0.558)\tLoss 0.1486 (0.0908)\t\n",
      "Epoch: [6] [70/500]\tTime 0.521 (0.557)\tLoss 0.1110 (0.0898)\t\n",
      "Epoch: [6] [75/500]\tTime 0.522 (0.559)\tLoss 0.0252 (0.0906)\t\n",
      "Epoch: [6] [80/500]\tTime 0.521 (0.560)\tLoss 0.1600 (0.0910)\t\n",
      "Epoch: [6] [85/500]\tTime 0.523 (0.560)\tLoss 0.0928 (0.0894)\t\n",
      "Epoch: [6] [90/500]\tTime 0.538 (0.559)\tLoss 0.0736 (0.0872)\t\n",
      "Epoch: [6] [95/500]\tTime 0.553 (0.558)\tLoss 0.1362 (0.0891)\t\n",
      "Epoch: [6] [100/500]\tTime 0.550 (0.558)\tLoss 0.2511 (0.0909)\t\n",
      "Epoch: [6] [105/500]\tTime 0.553 (0.559)\tLoss 0.0377 (0.0897)\t\n",
      "Epoch: [6] [110/500]\tTime 0.534 (0.559)\tLoss 0.1266 (0.0889)\t\n",
      "Epoch: [6] [115/500]\tTime 0.567 (0.560)\tLoss 0.1557 (0.0886)\t\n",
      "Epoch: [6] [120/500]\tTime 0.565 (0.559)\tLoss 0.0915 (0.0903)\t\n",
      "Epoch: [6] [125/500]\tTime 0.530 (0.559)\tLoss 0.0980 (0.0897)\t\n",
      "Epoch: [6] [130/500]\tTime 0.681 (0.559)\tLoss 0.0571 (0.0890)\t\n",
      "Epoch: [6] [135/500]\tTime 0.555 (0.559)\tLoss 0.1579 (0.0910)\t\n",
      "Epoch: [6] [140/500]\tTime 0.522 (0.558)\tLoss 0.0730 (0.0900)\t\n",
      "Epoch: [6] [145/500]\tTime 0.528 (0.558)\tLoss 0.0828 (0.0896)\t\n",
      "Epoch: [6] [150/500]\tTime 0.568 (0.558)\tLoss 0.1954 (0.0914)\t\n",
      "Epoch: [6] [155/500]\tTime 0.534 (0.557)\tLoss 0.2092 (0.0919)\t\n",
      "Epoch: [6] [160/500]\tTime 0.556 (0.558)\tLoss 0.0962 (0.0916)\t\n",
      "Epoch: [6] [165/500]\tTime 0.553 (0.559)\tLoss 0.1884 (0.0934)\t\n",
      "Epoch: [6] [170/500]\tTime 0.586 (0.559)\tLoss 0.0253 (0.0930)\t\n",
      "Epoch: [6] [175/500]\tTime 0.551 (0.559)\tLoss 0.1674 (0.0935)\t\n",
      "Epoch: [6] [180/500]\tTime 0.551 (0.558)\tLoss 0.0925 (0.0941)\t\n",
      "Epoch: [6] [185/500]\tTime 0.542 (0.558)\tLoss 0.1501 (0.0937)\t\n",
      "Epoch: [6] [190/500]\tTime 0.559 (0.559)\tLoss 0.0359 (0.0939)\t\n",
      "Epoch: [6] [195/500]\tTime 0.541 (0.559)\tLoss 0.0687 (0.0933)\t\n",
      "Epoch: [6] [200/500]\tTime 0.542 (0.558)\tLoss 0.0446 (0.0936)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [6] [205/500]\tTime 0.588 (0.559)\tLoss 0.1056 (0.0935)\t\n",
      "Epoch: [6] [210/500]\tTime 0.585 (0.558)\tLoss 0.0715 (0.0924)\t\n",
      "Epoch: [6] [215/500]\tTime 0.569 (0.558)\tLoss 0.0533 (0.0915)\t\n",
      "Epoch: [6] [220/500]\tTime 0.556 (0.559)\tLoss 0.2780 (0.0925)\t\n",
      "Epoch: [6] [225/500]\tTime 0.570 (0.559)\tLoss 0.0897 (0.0929)\t\n",
      "Epoch: [6] [230/500]\tTime 0.555 (0.559)\tLoss 0.0357 (0.0920)\t\n",
      "Epoch: [6] [235/500]\tTime 0.554 (0.559)\tLoss 0.0636 (0.0920)\t\n",
      "Epoch: [6] [240/500]\tTime 0.542 (0.559)\tLoss 0.1198 (0.0924)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6] [245/500]\tTime 0.544 (0.558)\tLoss 0.0446 (0.0932)\t\n",
      "Epoch: [6] [250/500]\tTime 0.525 (0.559)\tLoss 0.0731 (0.0933)\t\n",
      "Epoch: [6] [255/500]\tTime 0.527 (0.559)\tLoss 0.1209 (0.0934)\t\n",
      "Epoch: [6] [260/500]\tTime 0.543 (0.559)\tLoss 0.1460 (0.0932)\t\n",
      "Epoch: [6] [265/500]\tTime 0.543 (0.559)\tLoss 0.0769 (0.0931)\t\n",
      "Epoch: [6] [270/500]\tTime 0.529 (0.559)\tLoss 0.0545 (0.0936)\t\n",
      "Epoch: [6] [275/500]\tTime 0.572 (0.559)\tLoss 0.0367 (0.0935)\t\n",
      "Epoch: [6] [280/500]\tTime 0.527 (0.559)\tLoss 0.0660 (0.0936)\t\n",
      "Epoch: [6] [285/500]\tTime 0.580 (0.560)\tLoss 0.1028 (0.0941)\t\n",
      "Epoch: [6] [290/500]\tTime 0.554 (0.560)\tLoss 0.0275 (0.0937)\t\n",
      "Epoch: [6] [295/500]\tTime 0.556 (0.560)\tLoss 0.0711 (0.0937)\t\n",
      "Epoch: [6] [300/500]\tTime 0.558 (0.560)\tLoss 0.1225 (0.0942)\t\n",
      "Epoch: [6] [305/500]\tTime 0.587 (0.560)\tLoss 0.2164 (0.0942)\t\n",
      "Epoch: [6] [310/500]\tTime 0.566 (0.560)\tLoss 0.0596 (0.0938)\t\n",
      "Epoch: [6] [315/500]\tTime 0.556 (0.561)\tLoss 0.0861 (0.0938)\t\n",
      "Epoch: [6] [320/500]\tTime 0.569 (0.561)\tLoss 0.1567 (0.0945)\t\n",
      "Epoch: [6] [325/500]\tTime 0.540 (0.560)\tLoss 0.1134 (0.0944)\t\n",
      "Epoch: [6] [330/500]\tTime 0.558 (0.560)\tLoss 0.1276 (0.0949)\t\n",
      "Epoch: [6] [335/500]\tTime 0.552 (0.560)\tLoss 0.0782 (0.0946)\t\n",
      "Epoch: [6] [340/500]\tTime 0.543 (0.560)\tLoss 0.1186 (0.0946)\t\n",
      "Epoch: [6] [345/500]\tTime 0.542 (0.560)\tLoss 0.0480 (0.0951)\t\n",
      "Epoch: [6] [350/500]\tTime 0.547 (0.560)\tLoss 0.2961 (0.0955)\t\n",
      "Epoch: [6] [355/500]\tTime 0.558 (0.560)\tLoss 0.0972 (0.0959)\t\n",
      "Epoch: [6] [360/500]\tTime 0.705 (0.561)\tLoss 0.1177 (0.0962)\t\n",
      "Epoch: [6] [365/500]\tTime 0.543 (0.561)\tLoss 0.0617 (0.0959)\t\n",
      "Epoch: [6] [370/500]\tTime 0.527 (0.561)\tLoss 0.1620 (0.0962)\t\n",
      "Epoch: [6] [375/500]\tTime 0.562 (0.560)\tLoss 0.1697 (0.0965)\t\n",
      "Epoch: [6] [380/500]\tTime 0.554 (0.560)\tLoss 0.3043 (0.0972)\t\n",
      "Epoch: [6] [385/500]\tTime 0.580 (0.560)\tLoss 0.1314 (0.0974)\t\n",
      "Epoch: [6] [390/500]\tTime 0.569 (0.560)\tLoss 0.1278 (0.0975)\t\n",
      "Epoch: [6] [395/500]\tTime 0.554 (0.561)\tLoss 0.0479 (0.0973)\t\n",
      "Epoch: [6] [400/500]\tTime 0.570 (0.561)\tLoss 0.1362 (0.0976)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [6] [405/500]\tTime 0.524 (0.561)\tLoss 0.1830 (0.0981)\t\n",
      "Epoch: [6] [410/500]\tTime 0.543 (0.560)\tLoss 0.1215 (0.0985)\t\n",
      "Epoch: [6] [415/500]\tTime 0.507 (0.561)\tLoss 0.1286 (0.0987)\t\n",
      "Epoch: [6] [420/500]\tTime 0.559 (0.561)\tLoss 0.0607 (0.0993)\t\n",
      "Epoch: [6] [425/500]\tTime 0.584 (0.561)\tLoss 0.0914 (0.0998)\t\n",
      "Epoch: [6] [430/500]\tTime 0.576 (0.561)\tLoss 0.1264 (0.1003)\t\n",
      "Epoch: [6] [435/500]\tTime 0.541 (0.561)\tLoss 0.1716 (0.1005)\t\n",
      "Epoch: [6] [440/500]\tTime 0.558 (0.561)\tLoss 0.2948 (0.1013)\t\n",
      "Epoch: [6] [445/500]\tTime 0.538 (0.561)\tLoss 0.0355 (0.1018)\t\n",
      "Epoch: [6] [450/500]\tTime 0.540 (0.561)\tLoss 0.1220 (0.1021)\t\n",
      "Epoch: [6] [455/500]\tTime 0.555 (0.560)\tLoss 0.0508 (0.1019)\t\n",
      "Epoch: [6] [460/500]\tTime 0.556 (0.560)\tLoss 0.0899 (0.1015)\t\n",
      "Epoch: [6] [465/500]\tTime 0.528 (0.560)\tLoss 0.1213 (0.1014)\t\n",
      "Epoch: [6] [470/500]\tTime 0.563 (0.560)\tLoss 0.1319 (0.1013)\t\n",
      "Epoch: [6] [475/500]\tTime 0.542 (0.560)\tLoss 0.1109 (0.1010)\t\n",
      "Epoch: [6] [480/500]\tTime 0.529 (0.561)\tLoss 0.2908 (0.1017)\t\n",
      "Epoch: [6] [485/500]\tTime 0.525 (0.561)\tLoss 0.0747 (0.1017)\t\n",
      "Epoch: [6] [490/500]\tTime 0.543 (0.561)\tLoss 0.0918 (0.1016)\t\n",
      "Epoch: [6] [495/500]\tTime 0.694 (0.561)\tLoss 0.3524 (0.1022)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [7] [0/500]\tTime 0.582 (0.582)\tLoss 0.0178 (0.0178)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [7] [5/500]\tTime 0.548 (0.564)\tLoss 0.0611 (0.0546)\t\n",
      "Epoch: [7] [10/500]\tTime 0.542 (0.558)\tLoss 0.0186 (0.0584)\t\n",
      "Epoch: [7] [15/500]\tTime 0.571 (0.558)\tLoss 0.1213 (0.0640)\t\n",
      "Epoch: [7] [20/500]\tTime 0.524 (0.557)\tLoss 0.0990 (0.0668)\t\n",
      "Epoch: [7] [25/500]\tTime 0.544 (0.557)\tLoss 0.0745 (0.0683)\t\n",
      "Epoch: [7] [30/500]\tTime 0.551 (0.556)\tLoss 0.0394 (0.0705)\t\n",
      "Epoch: [7] [35/500]\tTime 0.569 (0.555)\tLoss 0.0302 (0.0740)\t\n",
      "Epoch: [7] [40/500]\tTime 0.571 (0.556)\tLoss 0.1046 (0.0750)\t\n",
      "Epoch: [7] [45/500]\tTime 0.576 (0.559)\tLoss 0.0727 (0.0758)\t\n",
      "Epoch: [7] [50/500]\tTime 0.701 (0.562)\tLoss 0.0544 (0.0753)\t\n",
      "Epoch: [7] [55/500]\tTime 0.533 (0.562)\tLoss 0.0564 (0.0733)\t\n",
      "Epoch: [7] [60/500]\tTime 0.536 (0.561)\tLoss 0.0625 (0.0734)\t\n",
      "Epoch: [7] [65/500]\tTime 0.552 (0.560)\tLoss 0.0517 (0.0738)\t\n",
      "Epoch: [7] [70/500]\tTime 0.541 (0.559)\tLoss 0.0920 (0.0734)\t\n",
      "Epoch: [7] [75/500]\tTime 0.545 (0.558)\tLoss 0.1853 (0.0778)\t\n",
      "Epoch: [7] [80/500]\tTime 0.522 (0.560)\tLoss 0.0773 (0.0771)\t\n",
      "Epoch: [7] [85/500]\tTime 0.560 (0.560)\tLoss 0.0870 (0.0764)\t\n",
      "Epoch: [7] [90/500]\tTime 0.588 (0.560)\tLoss 0.0525 (0.0762)\t\n",
      "Epoch: [7] [95/500]\tTime 0.539 (0.559)\tLoss 0.0927 (0.0767)\t\n",
      "Epoch: [7] [100/500]\tTime 0.553 (0.559)\tLoss 0.1803 (0.0771)\t\n",
      "Epoch: [7] [105/500]\tTime 0.555 (0.559)\tLoss 0.0498 (0.0761)\t\n",
      "Epoch: [7] [110/500]\tTime 0.535 (0.558)\tLoss 0.0831 (0.0771)\t\n",
      "Epoch: [7] [115/500]\tTime 0.536 (0.558)\tLoss 0.1388 (0.0773)\t\n",
      "Epoch: [7] [120/500]\tTime 0.533 (0.558)\tLoss 0.0278 (0.0771)\t\n",
      "Epoch: [7] [125/500]\tTime 0.588 (0.558)\tLoss 0.0612 (0.0756)\t\n",
      "Epoch: [7] [130/500]\tTime 0.554 (0.557)\tLoss 0.1635 (0.0776)\t\n",
      "Epoch: [7] [135/500]\tTime 0.542 (0.557)\tLoss 0.1718 (0.0778)\t\n",
      "Epoch: [7] [140/500]\tTime 0.543 (0.557)\tLoss 0.0256 (0.0794)\t\n",
      "Epoch: [7] [145/500]\tTime 0.559 (0.557)\tLoss 0.1186 (0.0802)\t\n",
      "Epoch: [7] [150/500]\tTime 1.068 (0.566)\tLoss 0.1514 (0.0812)\t\n",
      "Epoch: [7] [155/500]\tTime 0.785 (0.568)\tLoss 0.0641 (0.0811)\t\n",
      "Epoch: [7] [160/500]\tTime 0.571 (0.574)\tLoss 0.0912 (0.0816)\t\n",
      "Epoch: [7] [165/500]\tTime 0.727 (0.577)\tLoss 0.0930 (0.0814)\t\n",
      "Epoch: [7] [170/500]\tTime 0.541 (0.581)\tLoss 0.0765 (0.0822)\t\n",
      "Epoch: [7] [175/500]\tTime 0.536 (0.581)\tLoss 0.1579 (0.0822)\t\n",
      "Epoch: [7] [180/500]\tTime 0.564 (0.581)\tLoss 0.0508 (0.0813)\t\n",
      "Epoch: [7] [185/500]\tTime 0.552 (0.583)\tLoss 0.0690 (0.0811)\t\n",
      "Epoch: [7] [190/500]\tTime 0.672 (0.584)\tLoss 0.0269 (0.0818)\t\n",
      "Epoch: [7] [195/500]\tTime 0.736 (0.587)\tLoss 0.0897 (0.0819)\t\n",
      "Epoch: [7] [200/500]\tTime 0.592 (0.590)\tLoss 0.0260 (0.0810)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [7] [205/500]\tTime 0.732 (0.591)\tLoss 0.0417 (0.0812)\t\n",
      "Epoch: [7] [210/500]\tTime 0.557 (0.592)\tLoss 0.0812 (0.0810)\t\n",
      "Epoch: [7] [215/500]\tTime 0.553 (0.592)\tLoss 0.0562 (0.0806)\t\n",
      "Epoch: [7] [220/500]\tTime 0.550 (0.591)\tLoss 0.1483 (0.0805)\t\n",
      "Epoch: [7] [225/500]\tTime 0.605 (0.591)\tLoss 0.1368 (0.0810)\t\n",
      "Epoch: [7] [230/500]\tTime 0.651 (0.593)\tLoss 0.1104 (0.0812)\t\n",
      "Epoch: [7] [235/500]\tTime 0.967 (0.596)\tLoss 0.1354 (0.0820)\t\n",
      "Epoch: [7] [240/500]\tTime 0.906 (0.601)\tLoss 0.0640 (0.0826)\t\n",
      "Epoch: [7] [245/500]\tTime 0.817 (0.606)\tLoss 0.0572 (0.0827)\t\n",
      "Epoch: [7] [250/500]\tTime 0.872 (0.610)\tLoss 0.0887 (0.0822)\t\n",
      "Epoch: [7] [255/500]\tTime 0.752 (0.614)\tLoss 0.1169 (0.0826)\t\n",
      "Epoch: [7] [260/500]\tTime 0.720 (0.617)\tLoss 0.0289 (0.0828)\t\n",
      "Epoch: [7] [265/500]\tTime 0.813 (0.620)\tLoss 0.1199 (0.0845)\t\n",
      "Epoch: [7] [270/500]\tTime 0.798 (0.624)\tLoss 0.0689 (0.0855)\t\n",
      "Epoch: [7] [275/500]\tTime 0.854 (0.627)\tLoss 0.1004 (0.0854)\t\n",
      "Epoch: [7] [280/500]\tTime 0.764 (0.630)\tLoss 0.0970 (0.0855)\t\n",
      "Epoch: [7] [285/500]\tTime 0.832 (0.634)\tLoss 0.1065 (0.0858)\t\n",
      "Epoch: [7] [290/500]\tTime 0.761 (0.637)\tLoss 0.0843 (0.0853)\t\n",
      "Epoch: [7] [295/500]\tTime 0.758 (0.639)\tLoss 0.0519 (0.0856)\t\n",
      "Epoch: [7] [300/500]\tTime 0.762 (0.642)\tLoss 0.0647 (0.0852)\t\n",
      "Epoch: [7] [305/500]\tTime 0.784 (0.643)\tLoss 0.0424 (0.0857)\t\n",
      "Epoch: [7] [310/500]\tTime 0.729 (0.646)\tLoss 0.1099 (0.0853)\t\n",
      "Epoch: [7] [315/500]\tTime 0.776 (0.648)\tLoss 0.1663 (0.0865)\t\n",
      "Epoch: [7] [320/500]\tTime 0.793 (0.650)\tLoss 0.0657 (0.0862)\t\n",
      "Epoch: [7] [325/500]\tTime 0.729 (0.651)\tLoss 0.1376 (0.0859)\t\n",
      "Epoch: [7] [330/500]\tTime 0.797 (0.653)\tLoss 0.0438 (0.0860)\t\n",
      "Epoch: [7] [335/500]\tTime 0.752 (0.655)\tLoss 0.0171 (0.0856)\t\n",
      "Epoch: [7] [340/500]\tTime 0.756 (0.657)\tLoss 0.1086 (0.0853)\t\n",
      "Epoch: [7] [345/500]\tTime 0.757 (0.658)\tLoss 0.0364 (0.0850)\t\n",
      "Epoch: [7] [350/500]\tTime 0.815 (0.660)\tLoss 0.0395 (0.0852)\t\n",
      "Epoch: [7] [355/500]\tTime 0.744 (0.662)\tLoss 0.0188 (0.0851)\t\n",
      "Epoch: [7] [360/500]\tTime 0.778 (0.663)\tLoss 0.1496 (0.0857)\t\n",
      "Epoch: [7] [365/500]\tTime 0.721 (0.664)\tLoss 0.0992 (0.0853)\t\n",
      "Epoch: [7] [370/500]\tTime 0.766 (0.665)\tLoss 0.0517 (0.0853)\t\n",
      "Epoch: [7] [375/500]\tTime 0.741 (0.667)\tLoss 0.0930 (0.0855)\t\n",
      "Epoch: [7] [380/500]\tTime 0.733 (0.668)\tLoss 0.0239 (0.0854)\t\n",
      "Epoch: [7] [385/500]\tTime 0.726 (0.669)\tLoss 0.0808 (0.0851)\t\n",
      "Epoch: [7] [390/500]\tTime 0.759 (0.670)\tLoss 0.1047 (0.0856)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7] [395/500]\tTime 0.766 (0.671)\tLoss 0.0785 (0.0862)\t\n",
      "Epoch: [7] [400/500]\tTime 0.735 (0.673)\tLoss 0.2632 (0.0864)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [7] [405/500]\tTime 0.747 (0.674)\tLoss 0.2733 (0.0868)\t\n",
      "Epoch: [7] [410/500]\tTime 0.802 (0.675)\tLoss 0.0954 (0.0868)\t\n",
      "Epoch: [7] [415/500]\tTime 0.752 (0.676)\tLoss 0.1155 (0.0865)\t\n",
      "Epoch: [7] [420/500]\tTime 0.760 (0.677)\tLoss 0.1914 (0.0874)\t\n",
      "Epoch: [7] [425/500]\tTime 0.561 (0.677)\tLoss 0.0267 (0.0877)\t\n",
      "Epoch: [7] [430/500]\tTime 1.040 (0.677)\tLoss 0.0446 (0.0878)\t\n",
      "Epoch: [7] [435/500]\tTime 0.524 (0.677)\tLoss 0.2326 (0.0887)\t\n",
      "Epoch: [7] [440/500]\tTime 0.553 (0.675)\tLoss 0.0755 (0.0888)\t\n",
      "Epoch: [7] [445/500]\tTime 0.542 (0.674)\tLoss 0.2511 (0.0895)\t\n",
      "Epoch: [7] [450/500]\tTime 0.804 (0.674)\tLoss 0.1772 (0.0898)\t\n",
      "Epoch: [7] [455/500]\tTime 0.579 (0.674)\tLoss 0.0989 (0.0900)\t\n",
      "Epoch: [7] [460/500]\tTime 0.759 (0.675)\tLoss 0.1391 (0.0903)\t\n",
      "Epoch: [7] [465/500]\tTime 0.804 (0.675)\tLoss 0.0841 (0.0901)\t\n",
      "Epoch: [7] [470/500]\tTime 0.553 (0.675)\tLoss 0.0312 (0.0903)\t\n",
      "Epoch: [7] [475/500]\tTime 0.552 (0.674)\tLoss 0.1234 (0.0902)\t\n",
      "Epoch: [7] [480/500]\tTime 0.808 (0.674)\tLoss 0.1846 (0.0911)\t\n",
      "Epoch: [7] [485/500]\tTime 0.809 (0.674)\tLoss 0.0496 (0.0911)\t\n",
      "Epoch: [7] [490/500]\tTime 0.548 (0.674)\tLoss 0.1240 (0.0911)\t\n",
      "Epoch: [7] [495/500]\tTime 0.532 (0.676)\tLoss 0.1450 (0.0916)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [8] [0/500]\tTime 0.576 (0.576)\tLoss 0.0743 (0.0743)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [8] [5/500]\tTime 0.569 (0.614)\tLoss 0.0060 (0.0519)\t\n",
      "Epoch: [8] [10/500]\tTime 0.538 (0.585)\tLoss 0.0416 (0.0623)\t\n",
      "Epoch: [8] [15/500]\tTime 0.541 (0.576)\tLoss 0.0248 (0.0596)\t\n",
      "Epoch: [8] [20/500]\tTime 0.792 (0.593)\tLoss 0.0520 (0.0624)\t\n",
      "Epoch: [8] [25/500]\tTime 0.526 (0.603)\tLoss 0.0994 (0.0680)\t\n",
      "Epoch: [8] [30/500]\tTime 0.531 (0.594)\tLoss 0.0335 (0.0625)\t\n",
      "Epoch: [8] [35/500]\tTime 0.559 (0.589)\tLoss 0.0591 (0.0680)\t\n",
      "Epoch: [8] [40/500]\tTime 0.553 (0.584)\tLoss 0.0970 (0.0672)\t\n",
      "Epoch: [8] [45/500]\tTime 0.543 (0.584)\tLoss 0.0277 (0.0644)\t\n",
      "Epoch: [8] [50/500]\tTime 0.753 (0.593)\tLoss 0.0425 (0.0678)\t\n",
      "Epoch: [8] [55/500]\tTime 0.536 (0.599)\tLoss 0.0430 (0.0653)\t\n",
      "Epoch: [8] [60/500]\tTime 0.557 (0.595)\tLoss 0.0411 (0.0651)\t\n",
      "Epoch: [8] [65/500]\tTime 0.540 (0.591)\tLoss 0.0771 (0.0660)\t\n",
      "Epoch: [8] [70/500]\tTime 0.532 (0.587)\tLoss 0.0203 (0.0655)\t\n",
      "Epoch: [8] [75/500]\tTime 0.542 (0.584)\tLoss 0.0725 (0.0645)\t\n",
      "Epoch: [8] [80/500]\tTime 0.525 (0.582)\tLoss 0.0642 (0.0666)\t\n",
      "Epoch: [8] [85/500]\tTime 0.542 (0.581)\tLoss 0.0416 (0.0653)\t\n",
      "Epoch: [8] [90/500]\tTime 0.554 (0.579)\tLoss 0.0901 (0.0666)\t\n",
      "Epoch: [8] [95/500]\tTime 0.556 (0.578)\tLoss 0.0184 (0.0668)\t\n",
      "Epoch: [8] [100/500]\tTime 0.566 (0.576)\tLoss 0.1027 (0.0682)\t\n",
      "Epoch: [8] [105/500]\tTime 0.554 (0.575)\tLoss 0.0491 (0.0713)\t\n",
      "Epoch: [8] [110/500]\tTime 0.587 (0.575)\tLoss 0.0153 (0.0717)\t\n",
      "Epoch: [8] [115/500]\tTime 0.553 (0.574)\tLoss 0.1151 (0.0718)\t\n",
      "Epoch: [8] [120/500]\tTime 0.565 (0.573)\tLoss 0.0141 (0.0722)\t\n",
      "Epoch: [8] [125/500]\tTime 0.525 (0.572)\tLoss 0.1271 (0.0729)\t\n",
      "Epoch: [8] [130/500]\tTime 0.542 (0.572)\tLoss 0.0358 (0.0732)\t\n",
      "Epoch: [8] [135/500]\tTime 0.559 (0.571)\tLoss 0.1864 (0.0737)\t\n",
      "Epoch: [8] [140/500]\tTime 0.535 (0.570)\tLoss 0.1248 (0.0743)\t\n",
      "Epoch: [8] [145/500]\tTime 0.537 (0.570)\tLoss 0.2025 (0.0756)\t\n",
      "Epoch: [8] [150/500]\tTime 0.556 (0.569)\tLoss 0.1258 (0.0753)\t\n",
      "Epoch: [8] [155/500]\tTime 0.557 (0.568)\tLoss 0.0432 (0.0750)\t\n",
      "Epoch: [8] [160/500]\tTime 0.541 (0.567)\tLoss 0.0378 (0.0749)\t\n",
      "Epoch: [8] [165/500]\tTime 0.530 (0.567)\tLoss 0.2278 (0.0766)\t\n",
      "Epoch: [8] [170/500]\tTime 0.530 (0.567)\tLoss 0.0479 (0.0762)\t\n",
      "Epoch: [8] [175/500]\tTime 0.544 (0.567)\tLoss 0.0492 (0.0759)\t\n",
      "Epoch: [8] [180/500]\tTime 0.528 (0.567)\tLoss 0.0293 (0.0755)\t\n",
      "Epoch: [8] [185/500]\tTime 0.560 (0.566)\tLoss 0.1185 (0.0759)\t\n",
      "Epoch: [8] [190/500]\tTime 0.558 (0.566)\tLoss 0.1870 (0.0777)\t\n",
      "Epoch: [8] [195/500]\tTime 0.538 (0.566)\tLoss 0.1753 (0.0783)\t\n",
      "Epoch: [8] [200/500]\tTime 0.557 (0.565)\tLoss 0.0148 (0.0797)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [8] [205/500]\tTime 0.545 (0.565)\tLoss 0.0683 (0.0796)\t\n",
      "Epoch: [8] [210/500]\tTime 0.533 (0.565)\tLoss 0.1377 (0.0798)\t\n",
      "Epoch: [8] [215/500]\tTime 0.528 (0.565)\tLoss 0.0571 (0.0803)\t\n",
      "Epoch: [8] [220/500]\tTime 0.551 (0.564)\tLoss 0.1047 (0.0807)\t\n",
      "Epoch: [8] [225/500]\tTime 0.573 (0.564)\tLoss 0.0671 (0.0810)\t\n",
      "Epoch: [8] [230/500]\tTime 0.995 (0.567)\tLoss 0.0670 (0.0810)\t\n",
      "Epoch: [8] [235/500]\tTime 0.566 (0.567)\tLoss 0.2286 (0.0817)\t\n",
      "Epoch: [8] [240/500]\tTime 0.560 (0.567)\tLoss 0.1336 (0.0824)\t\n",
      "Epoch: [8] [245/500]\tTime 0.542 (0.567)\tLoss 0.2208 (0.0827)\t\n",
      "Epoch: [8] [250/500]\tTime 0.526 (0.566)\tLoss 0.2437 (0.0839)\t\n",
      "Epoch: [8] [255/500]\tTime 0.539 (0.566)\tLoss 0.0599 (0.0843)\t\n",
      "Epoch: [8] [260/500]\tTime 0.556 (0.566)\tLoss 0.1351 (0.0852)\t\n",
      "Epoch: [8] [265/500]\tTime 0.555 (0.565)\tLoss 0.0968 (0.0856)\t\n",
      "Epoch: [8] [270/500]\tTime 0.571 (0.565)\tLoss 0.1720 (0.0860)\t\n",
      "Epoch: [8] [275/500]\tTime 0.596 (0.565)\tLoss 0.0990 (0.0860)\t\n",
      "Epoch: [8] [280/500]\tTime 0.565 (0.565)\tLoss 0.1327 (0.0857)\t\n",
      "Epoch: [8] [285/500]\tTime 0.553 (0.565)\tLoss 0.0257 (0.0863)\t\n",
      "Epoch: [8] [290/500]\tTime 0.545 (0.565)\tLoss 0.0509 (0.0858)\t\n",
      "Epoch: [8] [295/500]\tTime 0.526 (0.565)\tLoss 0.1893 (0.0862)\t\n",
      "Epoch: [8] [300/500]\tTime 0.547 (0.564)\tLoss 0.0657 (0.0861)\t\n",
      "Epoch: [8] [305/500]\tTime 0.547 (0.564)\tLoss 0.0641 (0.0861)\t\n",
      "Epoch: [8] [310/500]\tTime 0.578 (0.564)\tLoss 0.1007 (0.0871)\t\n",
      "Epoch: [8] [315/500]\tTime 0.574 (0.564)\tLoss 0.1480 (0.0871)\t\n",
      "Epoch: [8] [320/500]\tTime 0.556 (0.564)\tLoss 0.0786 (0.0873)\t\n",
      "Epoch: [8] [325/500]\tTime 0.537 (0.564)\tLoss 0.0798 (0.0875)\t\n",
      "Epoch: [8] [330/500]\tTime 0.553 (0.563)\tLoss 0.1005 (0.0875)\t\n",
      "Epoch: [8] [335/500]\tTime 0.543 (0.563)\tLoss 0.0688 (0.0879)\t\n",
      "Epoch: [8] [340/500]\tTime 0.543 (0.563)\tLoss 0.0680 (0.0880)\t\n",
      "Epoch: [8] [345/500]\tTime 0.544 (0.563)\tLoss 0.1032 (0.0881)\t\n",
      "Epoch: [8] [350/500]\tTime 0.527 (0.563)\tLoss 0.2045 (0.0880)\t\n",
      "Epoch: [8] [355/500]\tTime 0.531 (0.563)\tLoss 0.0731 (0.0879)\t\n",
      "Epoch: [8] [360/500]\tTime 0.520 (0.562)\tLoss 0.1214 (0.0878)\t\n",
      "Epoch: [8] [365/500]\tTime 0.555 (0.562)\tLoss 0.0528 (0.0877)\t\n",
      "Epoch: [8] [370/500]\tTime 0.539 (0.562)\tLoss 0.0663 (0.0875)\t\n",
      "Epoch: [8] [375/500]\tTime 0.592 (0.562)\tLoss 0.1409 (0.0873)\t\n",
      "Epoch: [8] [380/500]\tTime 0.576 (0.562)\tLoss 0.0223 (0.0874)\t\n",
      "Epoch: [8] [385/500]\tTime 0.545 (0.562)\tLoss 0.0231 (0.0875)\t\n",
      "Epoch: [8] [390/500]\tTime 0.542 (0.562)\tLoss 0.1540 (0.0878)\t\n",
      "Epoch: [8] [395/500]\tTime 0.557 (0.562)\tLoss 0.0379 (0.0879)\t\n",
      "Epoch: [8] [400/500]\tTime 0.544 (0.561)\tLoss 0.1657 (0.0886)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [8] [405/500]\tTime 0.558 (0.561)\tLoss 0.1454 (0.0895)\t\n",
      "Epoch: [8] [410/500]\tTime 0.569 (0.561)\tLoss 0.1199 (0.0898)\t\n",
      "Epoch: [8] [415/500]\tTime 0.552 (0.561)\tLoss 0.0578 (0.0898)\t\n",
      "Epoch: [8] [420/500]\tTime 1.041 (0.563)\tLoss 0.0306 (0.0899)\t\n",
      "Epoch: [8] [425/500]\tTime 1.329 (0.568)\tLoss 0.2512 (0.0904)\t\n",
      "Epoch: [8] [430/500]\tTime 0.946 (0.571)\tLoss 0.0345 (0.0902)\t\n",
      "Epoch: [8] [435/500]\tTime 0.566 (0.571)\tLoss 0.1118 (0.0909)\t\n",
      "Epoch: [8] [440/500]\tTime 0.556 (0.571)\tLoss 0.1790 (0.0912)\t\n",
      "Epoch: [8] [445/500]\tTime 0.556 (0.571)\tLoss 0.2032 (0.0916)\t\n",
      "Epoch: [8] [450/500]\tTime 0.538 (0.571)\tLoss 0.0638 (0.0919)\t\n",
      "Epoch: [8] [455/500]\tTime 0.542 (0.571)\tLoss 0.0775 (0.0919)\t\n",
      "Epoch: [8] [460/500]\tTime 0.580 (0.571)\tLoss 0.1046 (0.0920)\t\n",
      "Epoch: [8] [465/500]\tTime 0.527 (0.570)\tLoss 0.1200 (0.0925)\t\n",
      "Epoch: [8] [470/500]\tTime 0.528 (0.570)\tLoss 0.0658 (0.0926)\t\n",
      "Epoch: [8] [475/500]\tTime 0.526 (0.570)\tLoss 0.0554 (0.0924)\t\n",
      "Epoch: [8] [480/500]\tTime 0.559 (0.570)\tLoss 0.0985 (0.0926)\t\n",
      "Epoch: [8] [485/500]\tTime 0.574 (0.570)\tLoss 0.1668 (0.0930)\t\n",
      "Epoch: [8] [490/500]\tTime 0.534 (0.569)\tLoss 0.1383 (0.0933)\t\n",
      "Epoch: [8] [495/500]\tTime 0.534 (0.569)\tLoss 0.1713 (0.0933)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [9] [0/500]\tTime 0.557 (0.557)\tLoss 0.0856 (0.0856)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [9] [5/500]\tTime 0.557 (0.558)\tLoss 0.0144 (0.0772)\t\n",
      "Epoch: [9] [10/500]\tTime 0.537 (0.552)\tLoss 0.0669 (0.0696)\t\n",
      "Epoch: [9] [15/500]\tTime 0.552 (0.555)\tLoss 0.1157 (0.0805)\t\n",
      "Epoch: [9] [20/500]\tTime 0.562 (0.553)\tLoss 0.0648 (0.0832)\t\n",
      "Epoch: [9] [25/500]\tTime 0.542 (0.552)\tLoss 0.0275 (0.0784)\t\n",
      "Epoch: [9] [30/500]\tTime 0.540 (0.553)\tLoss 0.1054 (0.0828)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9] [35/500]\tTime 0.559 (0.554)\tLoss 0.0579 (0.0833)\t\n",
      "Epoch: [9] [40/500]\tTime 0.531 (0.553)\tLoss 0.0450 (0.0795)\t\n",
      "Epoch: [9] [45/500]\tTime 0.572 (0.553)\tLoss 0.0446 (0.0812)\t\n",
      "Epoch: [9] [50/500]\tTime 0.558 (0.553)\tLoss 0.0873 (0.0834)\t\n",
      "Epoch: [9] [55/500]\tTime 0.571 (0.553)\tLoss 0.0685 (0.0810)\t\n",
      "Epoch: [9] [60/500]\tTime 0.552 (0.553)\tLoss 0.0525 (0.0776)\t\n",
      "Epoch: [9] [65/500]\tTime 0.564 (0.553)\tLoss 0.0876 (0.0777)\t\n",
      "Epoch: [9] [70/500]\tTime 0.547 (0.553)\tLoss 0.0484 (0.0758)\t\n",
      "Epoch: [9] [75/500]\tTime 0.543 (0.553)\tLoss 0.1028 (0.0785)\t\n",
      "Epoch: [9] [80/500]\tTime 0.525 (0.552)\tLoss 0.0708 (0.0766)\t\n",
      "Epoch: [9] [85/500]\tTime 0.536 (0.552)\tLoss 0.1093 (0.0787)\t\n",
      "Epoch: [9] [90/500]\tTime 0.537 (0.552)\tLoss 0.0466 (0.0791)\t\n",
      "Epoch: [9] [95/500]\tTime 0.569 (0.552)\tLoss 0.1746 (0.0806)\t\n",
      "Epoch: [9] [100/500]\tTime 0.554 (0.552)\tLoss 0.0515 (0.0787)\t\n",
      "Epoch: [9] [105/500]\tTime 0.618 (0.552)\tLoss 0.0457 (0.0788)\t\n",
      "Epoch: [9] [110/500]\tTime 0.546 (0.552)\tLoss 0.0088 (0.0765)\t\n",
      "Epoch: [9] [115/500]\tTime 0.593 (0.552)\tLoss 0.0661 (0.0752)\t\n",
      "Epoch: [9] [120/500]\tTime 0.526 (0.552)\tLoss 0.0288 (0.0757)\t\n",
      "Epoch: [9] [125/500]\tTime 0.527 (0.552)\tLoss 0.0223 (0.0744)\t\n",
      "Epoch: [9] [130/500]\tTime 0.534 (0.552)\tLoss 0.0088 (0.0739)\t\n",
      "Epoch: [9] [135/500]\tTime 0.553 (0.552)\tLoss 0.0286 (0.0736)\t\n",
      "Epoch: [9] [140/500]\tTime 0.536 (0.552)\tLoss 0.0422 (0.0738)\t\n",
      "Epoch: [9] [145/500]\tTime 0.553 (0.552)\tLoss 0.0268 (0.0734)\t\n",
      "Epoch: [9] [150/500]\tTime 0.553 (0.552)\tLoss 0.0307 (0.0728)\t\n",
      "Epoch: [9] [155/500]\tTime 0.543 (0.552)\tLoss 0.0727 (0.0738)\t\n",
      "Epoch: [9] [160/500]\tTime 0.558 (0.552)\tLoss 0.0103 (0.0743)\t\n",
      "Epoch: [9] [165/500]\tTime 0.542 (0.552)\tLoss 0.0744 (0.0740)\t\n",
      "Epoch: [9] [170/500]\tTime 0.542 (0.552)\tLoss 0.0348 (0.0739)\t\n",
      "Epoch: [9] [175/500]\tTime 0.558 (0.552)\tLoss 0.0455 (0.0740)\t\n",
      "Epoch: [9] [180/500]\tTime 0.569 (0.552)\tLoss 0.0386 (0.0736)\t\n",
      "Epoch: [9] [185/500]\tTime 0.559 (0.552)\tLoss 0.1334 (0.0740)\t\n",
      "Epoch: [9] [190/500]\tTime 0.556 (0.552)\tLoss 0.0347 (0.0749)\t\n",
      "Epoch: [9] [195/500]\tTime 0.529 (0.552)\tLoss 0.0344 (0.0746)\t\n",
      "Epoch: [9] [200/500]\tTime 0.544 (0.552)\tLoss 0.0775 (0.0746)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [9] [205/500]\tTime 0.571 (0.552)\tLoss 0.1052 (0.0746)\t\n",
      "Epoch: [9] [210/500]\tTime 0.556 (0.552)\tLoss 0.1116 (0.0748)\t\n",
      "Epoch: [9] [215/500]\tTime 0.571 (0.552)\tLoss 0.0294 (0.0751)\t\n",
      "Epoch: [9] [220/500]\tTime 0.544 (0.552)\tLoss 0.0927 (0.0758)\t\n",
      "Epoch: [9] [225/500]\tTime 0.539 (0.553)\tLoss 0.2228 (0.0770)\t\n",
      "Epoch: [9] [230/500]\tTime 0.537 (0.552)\tLoss 0.1092 (0.0776)\t\n",
      "Epoch: [9] [235/500]\tTime 0.530 (0.552)\tLoss 0.0779 (0.0787)\t\n",
      "Epoch: [9] [240/500]\tTime 0.529 (0.552)\tLoss 0.0578 (0.0786)\t\n",
      "Epoch: [9] [245/500]\tTime 0.567 (0.552)\tLoss 0.0725 (0.0782)\t\n",
      "Epoch: [9] [250/500]\tTime 0.559 (0.552)\tLoss 0.0746 (0.0783)\t\n",
      "Epoch: [9] [255/500]\tTime 0.597 (0.552)\tLoss 0.0683 (0.0779)\t\n",
      "Epoch: [9] [260/500]\tTime 0.567 (0.553)\tLoss 0.1058 (0.0781)\t\n",
      "Epoch: [9] [265/500]\tTime 1.146 (0.559)\tLoss 0.0591 (0.0785)\t\n",
      "Epoch: [9] [270/500]\tTime 1.293 (0.569)\tLoss 0.0604 (0.0780)\t\n",
      "Epoch: [9] [275/500]\tTime 1.180 (0.581)\tLoss 0.0393 (0.0776)\t\n",
      "Epoch: [9] [280/500]\tTime 1.140 (0.592)\tLoss 0.2658 (0.0779)\t\n",
      "Epoch: [9] [285/500]\tTime 1.198 (0.602)\tLoss 0.0412 (0.0779)\t\n",
      "Epoch: [9] [290/500]\tTime 1.215 (0.612)\tLoss 0.0274 (0.0781)\t\n",
      "Epoch: [9] [295/500]\tTime 1.143 (0.621)\tLoss 0.1050 (0.0785)\t\n",
      "Epoch: [9] [300/500]\tTime 1.157 (0.630)\tLoss 0.3138 (0.0795)\t\n",
      "Epoch: [9] [305/500]\tTime 0.938 (0.638)\tLoss 0.0969 (0.0798)\t\n",
      "Epoch: [9] [310/500]\tTime 1.145 (0.644)\tLoss 0.0200 (0.0797)\t\n",
      "Epoch: [9] [315/500]\tTime 1.148 (0.653)\tLoss 0.2094 (0.0806)\t\n",
      "Epoch: [9] [320/500]\tTime 1.182 (0.661)\tLoss 0.0402 (0.0805)\t\n",
      "Epoch: [9] [325/500]\tTime 1.176 (0.669)\tLoss 0.2811 (0.0811)\t\n",
      "Epoch: [9] [330/500]\tTime 1.223 (0.678)\tLoss 0.0695 (0.0814)\t\n",
      "Epoch: [9] [335/500]\tTime 1.166 (0.686)\tLoss 0.0349 (0.0821)\t\n",
      "Epoch: [9] [340/500]\tTime 1.204 (0.693)\tLoss 0.0645 (0.0824)\t\n",
      "Epoch: [9] [345/500]\tTime 1.073 (0.700)\tLoss 0.0556 (0.0823)\t\n",
      "Epoch: [9] [350/500]\tTime 1.161 (0.705)\tLoss 0.1339 (0.0823)\t\n",
      "Epoch: [9] [355/500]\tTime 1.196 (0.712)\tLoss 0.1384 (0.0828)\t\n",
      "Epoch: [9] [360/500]\tTime 1.169 (0.719)\tLoss 0.0498 (0.0832)\t\n",
      "Epoch: [9] [365/500]\tTime 1.180 (0.725)\tLoss 0.2239 (0.0833)\t\n",
      "Epoch: [9] [370/500]\tTime 1.184 (0.731)\tLoss 0.1326 (0.0838)\t\n",
      "Epoch: [9] [375/500]\tTime 1.210 (0.737)\tLoss 0.1153 (0.0838)\t\n",
      "Epoch: [9] [380/500]\tTime 1.131 (0.743)\tLoss 0.1206 (0.0847)\t\n",
      "Epoch: [9] [385/500]\tTime 1.000 (0.747)\tLoss 0.1260 (0.0849)\t\n",
      "Epoch: [9] [390/500]\tTime 0.529 (0.747)\tLoss 0.1373 (0.0848)\t\n",
      "Epoch: [9] [395/500]\tTime 0.545 (0.745)\tLoss 0.1313 (0.0849)\t\n",
      "Epoch: [9] [400/500]\tTime 0.742 (0.743)\tLoss 0.1309 (0.0853)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n",
      "Epoch: [9] [405/500]\tTime 0.557 (0.742)\tLoss 0.0489 (0.0857)\t\n",
      "Epoch: [9] [410/500]\tTime 0.555 (0.740)\tLoss 0.0967 (0.0858)\t\n",
      "Epoch: [9] [415/500]\tTime 0.564 (0.737)\tLoss 0.1618 (0.0856)\t\n",
      "Epoch: [9] [420/500]\tTime 0.527 (0.735)\tLoss 0.0764 (0.0860)\t\n",
      "Epoch: [9] [425/500]\tTime 0.545 (0.733)\tLoss 0.1092 (0.0863)\t\n",
      "Epoch: [9] [430/500]\tTime 0.527 (0.731)\tLoss 0.0479 (0.0867)\t\n",
      "Epoch: [9] [435/500]\tTime 0.545 (0.729)\tLoss 0.1284 (0.0867)\t\n",
      "Epoch: [9] [440/500]\tTime 0.535 (0.727)\tLoss 0.0713 (0.0868)\t\n",
      "Epoch: [9] [445/500]\tTime 0.537 (0.725)\tLoss 0.0919 (0.0870)\t\n",
      "Epoch: [9] [450/500]\tTime 0.553 (0.723)\tLoss 0.1341 (0.0873)\t\n",
      "Epoch: [9] [455/500]\tTime 0.554 (0.721)\tLoss 0.2351 (0.0881)\t\n",
      "Epoch: [9] [460/500]\tTime 0.553 (0.719)\tLoss 0.1446 (0.0880)\t\n",
      "Epoch: [9] [465/500]\tTime 0.588 (0.718)\tLoss 0.0540 (0.0879)\t\n",
      "Epoch: [9] [470/500]\tTime 0.559 (0.716)\tLoss 0.0830 (0.0879)\t\n",
      "Epoch: [9] [475/500]\tTime 0.561 (0.714)\tLoss 0.1661 (0.0883)\t\n",
      "Epoch: [9] [480/500]\tTime 0.540 (0.713)\tLoss 0.1212 (0.0889)\t\n",
      "Epoch: [9] [485/500]\tTime 0.558 (0.711)\tLoss 0.1320 (0.0893)\t\n",
      "Epoch: [9] [490/500]\tTime 0.571 (0.709)\tLoss 0.0803 (0.0894)\t\n",
      "Epoch: [9] [495/500]\tTime 0.556 (0.708)\tLoss 0.1461 (0.0899)\t\n",
      "Saving Model...\n",
      "Model Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "\n",
    "EPOCH = 10\n",
    "PRINT_FREQ = 5\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train(encoder, decoder, epoch)\n",
    "    print('Saving Model...')\n",
    "    torch.save(encoder.state_dict(), 'eng2spa_encoder_params.pkl')\n",
    "    torch.save(decoder.state_dict(), 'eng2spa_decoder_params.pkl')\n",
    "    print('Model Saved Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_val = Encoder(vocab_inp_size, embedding_dim, units, 1)\n",
    "decoder_val = Decoder(vocab_tar_size, embedding_dim, units, units, 1)\n",
    "\n",
    "encoder_val.to(device)\n",
    "decoder_val.to(device)\n",
    "\n",
    "# print(encoder_val)\n",
    "\n",
    "encoder_val.load_state_dict(torch.load('eng2spa_encoder_params.pkl'))\n",
    "decoder_val.load_state_dict(torch.load('eng2spa_decoder_params.pkl'))\n",
    "\n",
    "# validate(encoder_val, decoder_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
